{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ! pip install gensim\n",
    "# ! pip install vaderSentiment\n",
    "# ! pip install text2emotion\n",
    "# ! pip install tqdm\n",
    "#! pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Monster\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import datetime\n",
    "import string\n",
    "import pickle\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Monster\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing stopwords and modifying as per the need\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('English')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use', 'said', 'reuters'])\n",
    "stop_words.remove(\"no\")\n",
    "stop_words.remove(\"not\")\n",
    "stop_words.remove(\"very\")\n",
    "stop_words.remove('nor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to handle missing values\n",
    "def missing_values(df):\n",
    "    return df.fillna(\" \", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to count number of stopwords present in the article\n",
    "def no_of_stopwords(phrase_list):\n",
    "    no_of_sw = 0\n",
    "    for token in phrase_list:\n",
    "        if token in gensim.parsing.preprocessing.STOPWORDS:\n",
    "            no_of_sw += 1\n",
    "    return no_of_sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to count number of question marks present in the article.\n",
    "def no_of_quesMarks(phrase):\n",
    "    i = 0\n",
    "    for char in phrase:\n",
    "        if char == '?':\n",
    "            i += 1\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to count number of exclamation marks present in the article.\n",
    "def no_of_exclamation(phrase):\n",
    "    i = 0\n",
    "    for char in phrase:\n",
    "        if char == '!':\n",
    "            i += 1\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parts of speech tagging....Here I am counting number of different pos present in the article\n",
    "from tqdm import tqdm\n",
    "def pos_tagging(df):\n",
    "    # Creating list to store count of different pos\n",
    "    cc_cd_lst =[]                   \n",
    "    determiner_lst = []\n",
    "    foreign_w_lst = []\n",
    "    conj_prep_lst = []\n",
    "    adjective_lst = []\n",
    "    modal_lst = []\n",
    "    noun_lst = []\n",
    "    adverb_lst = []\n",
    "    verb_lst = []\n",
    "    print(\"POS TAGGING\")\n",
    "    for article in tqdm(df):\n",
    "        lst = nltk.pos_tag(article.split()) # Using NLTK pos tagger\n",
    "        cc_cd = determiner = foreign_w = conj_prep = adjective = modal = noun =  adverb = verb = 0\n",
    "        for tag in lst:\n",
    "            if tag[1] in ['CC', 'CD']:\n",
    "                cc_cd += 1\n",
    "            elif tag[1] == 'DT':\n",
    "                determiner += 1\n",
    "            elif tag[1] == 'FW':\n",
    "                foreign_w += 1\n",
    "            elif tag[1] == 'IN':\n",
    "                conj_prep += 1\n",
    "            elif tag[1] in ['JJ', 'JJR', 'JJS']:\n",
    "                adjective += 1\n",
    "            elif tag[1] == 'MD':\n",
    "                modal += 1\n",
    "            elif tag[1] in ['NN', 'NNS', 'NP', 'NPS']:\n",
    "                noun += 1\n",
    "            elif tag[1] in ['RB','RBR','RBS','RP']:\n",
    "                adverb += 1\n",
    "            elif tag[1] in ['VB','VBD','VBG','VBN','VBP', 'VBZ']:\n",
    "                verb += 1\n",
    "        \n",
    "        cc_cd_lst.append(cc_cd)\n",
    "        determiner_lst.append(determiner)\n",
    "        foreign_w_lst.append(foreign_w)\n",
    "        conj_prep_lst.append(conj_prep)\n",
    "        adjective_lst.append(adjective)\n",
    "        modal_lst.append(modal)\n",
    "        noun_lst.append(noun)\n",
    "        adverb_lst.append(adverb)\n",
    "        verb_lst.append(verb)\n",
    "    return np.array([cc_cd_lst, determiner_lst, foreign_w_lst, conj_prep_lst, adjective_lst, modal_lst, noun_lst, adverb_lst, verb_lst]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/cjhutto/vaderSentiment#:~:text=Notifications-,VADER%20Sentiment%20Analysis.,on%20texts%20from%20other%20domains.\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "def sentiment_scores(sentence):\n",
    " \n",
    "    # Create a SentimentIntensityAnalyzer object. A polarity_scores method of SentimentIntensityAnalyzer\n",
    "    # {'neg': 0.198, 'neu': 0.652, 'pos': 0.149, 'compound': -0.9981}\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    sentiment_dict = sid_obj.polarity_scores(sentence) # return a dictionary which contains pos, neg, neu, and compound scores.\n",
    "    \n",
    "    if sentiment_dict['compound'] >= 0.05 :\n",
    "        x = \"Positive\"\n",
    " \n",
    "    elif sentiment_dict['compound'] <= - 0.05 :\n",
    "        x = \"Negative\"\n",
    " \n",
    "    else :\n",
    "        x = \"Neutral\"\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Monster\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Monster\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Monster\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import text2emotion as te\n",
    "def text2emotion(article):\n",
    "    emotion = te.get_emotion(article)\n",
    "    \n",
    "    return max(emotion, key = emotion.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. https://pdf.sciencedirectassets.com/280203/1-s2.0-S1877050920X00093/1-s2.0-S1877050920312394/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEC8aCXVzLWVhc3QtMSJGMEQCIAlAZ1MPWoqC4rON4Tfg8MWU71TWYnjLdInBbY3cAcK4AiACnKx8%2BuDCkZejlN8YLwlk8G2xSnnKFJ%2FHh%2FtJNBD3tyr6AwgXEAQaDDA1OTAwMzU0Njg2NSIMRt4D%2BkZ2rGCUyBEgKtcDFZasgD9rvzpzZ6%2FGdTDB9YYH3pXs9mnWdxssp00b1J9sGlvISw9r7c%2Fd%2BkDDlE3StYkt2uk4ISgFjWk1PAH%2BJvggVG2ViWqEZTiylRg760s%2Fa5Um9OQaTtAZZyWZeXoKR7mbeEBUklBFuAZE%2Bcu6V1sFXxaXV1dVQSULl7%2BFGk4t8dS2gOrmsBRYNGTciJLkxTcyl3nQ7d%2FQQhOA38sQWsGbyJHlXsBhMfzCbXlxIJIMJBe5h%2FcFknp%2FFpbzLFodhtoYYGwWrsVNWFrsbIaaSdTI7VpOM8shexgTocFgD%2F88Ntzd08CN1Jnqyga8mOeK%2Fv7hieZxTVnlekyDI1ZNwHB%2B0cBC%2FV1IFQrVwdW1SZ95LsMTAvw5J3HvjcN5eJZZFGq9JxIqn1Xvp%2B7oiWeEdZu0%2B0AAgcf%2BF7y4HeS%2FETTn4%2BTV3bCslJxRR96PfS2WQACNogAU%2Be%2F0LVdQzbraKNQ6D%2BYMeZx%2BYDnx6R0vyPjIDiMiuaTa5bhgBwr29eth9YZPN3U5WFSMPv5WXWNwPlyzhuFCZcnS%2Fnj1ZyJqTZob3KaPVWvI0jHVD%2BcR4r5kUSSI2SpSLfFvulIa5yxyLnTOZD8%2FmCeijIwUJGbjliwt8ljGFR%2FLMLHm0o0GOqYBYZ4cpKQv1Si2Jo94a%2FDkLukgjRh%2BTTqVkxt2Wh9QhuZEeI%2BjM6MvmztdtBkdY4%2FcQGxldw8En2y8WGq4awbKCo3juV21cXTRZGAQXUD43lO2bGF26%2F5ajqoh88eyOICd%2BsNH4ov6jsp375HQUOR0Ba%2FQK%2BbKqIqz2f3Cn%2FVZwVgf3%2B8LY%2BsjAnP%2BRlQmJNi00hH5JRE7N%2FPq4kDZjkNJPwuju5oWyA%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20211211T144440Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYT3WHAHFH%2F20211211%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=a29ac13a5f0a28d0462172bd3e198aa4d393427edcb15fcbbd96419cd645f82a&hash=1602c77c9d3c9c917ea7ed2f2a7125c4be8d9866b5b08f782e06db5f2a81217b&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S1877050920312394&tid=spdf-ede68e5d-fcc9-4bb5-b6eb-3ef3c523b8a5&sid=9c753a7092e7a44ca21ba6f0d3ae280a9ee2gxrqb&type=client\n",
    "\n",
    "2. https://medium.com/clement-ong/fake-news-detection-4713eb3b1cd6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting few features before removing stopwords/Lemmetization/special characters\n",
    "\n",
    "from nltk import sent_tokenize\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas()\n",
    "\n",
    "def prefeaturization(df):\n",
    "    df['cleaned_article'] = df['cleaned_article'].str.lower() # Converting string into lower\n",
    "       \n",
    "    print(\"Number of punctuations\") # Creating new feature of punctuation using string predefined punctuation method\n",
    "    df[\"num_punctuations\"] =df['cleaned_article'].progress_apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
    "    \n",
    "    # Calling above defined no_of_stopwards function for counting stopwords per article for feature creation\n",
    "    print('No of Stopwords')\n",
    "    df['no_of_stopwords'] = df['cleaned_article'].progress_apply(no_of_stopwords) \n",
    "    \n",
    "    print('No of question marks')\n",
    "    df['no_of_quesMarks'] = df['cleaned_article'].progress_apply(no_of_quesMarks)\n",
    "    \n",
    "    print(\"Number of Exclamation Marks\")\n",
    "    df['no_of_exclamation'] = df['cleaned_article'].progress_apply(no_of_exclamation)\n",
    "    \n",
    "    print(\"No of Sentences\")\n",
    "    df['no_of_sentence'] = df['cleaned_article'].progress_apply(sent_tokenize).apply(lambda x: len(x))\n",
    "    \n",
    "    \n",
    "    print(\"Sentiment Analysis\")\n",
    "    df['sentiment'] = df['cleaned_article'].progress_apply(sentiment_scores)\n",
    "    \n",
    "    #print(\"Text Emotion\")\n",
    "    #df['emotion'] = df['cleaned_article'].progress_apply(text2emotion)\n",
    "    pos = pd.DataFrame(pos_tagging(df['cleaned_article']), columns= ['cc_cd', 'determiner', 'foreign_w', 'conj_prep', 'adjective', 'modal', 'noun',  'adverb', 'verb'])\n",
    "    df_new = pd.concat([df, pos], axis = 1)\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "\n",
    "# Removing stop words and all those words which has length less than 3\n",
    "def preprocessing(phrase):\n",
    "    final_article = ''\n",
    "    for token in phrase.split():\n",
    "        if len(token)>3 and token not in stop_words:\n",
    "            final_article += token + ' '\n",
    "    return final_article.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing links\n",
    "import re\n",
    "def Link_removal(data):\n",
    "    return re.sub(\"http\\S+\", \"\", data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing html tags\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def Tag_removal(sentence):\n",
    "    soup = BeautifulSoup(sentence, 'html.parser')\n",
    "    text = soup.get_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting contraction words like was't, don't, etc. into normal english words like was not, do not etc.\n",
    "def Decontracted(sentence):\n",
    "    # Specific\n",
    "    sentence = re.sub(\"won't\", \"will not\", sentence)\n",
    "    sentence = re.sub(\"can't\", \"can not\", sentence)\n",
    "    \n",
    "    # General\n",
    "    sentence = re.sub(r\"n\\'t\", \" not\", sentence)\n",
    "    sentence = re.sub(r\"\\'re\", \" are\", sentence)\n",
    "    sentence = re.sub(r\"\\'s\", \" is\", sentence)\n",
    "    sentence = re.sub(r\"\\'d\", \" would\", sentence)\n",
    "    sentence = re.sub(r\"\\'ll\", \" will\", sentence)\n",
    "    sentence = re.sub(r\"\\'t\", \" not\", sentence)\n",
    "    sentence = re.sub(r\"\\'ve\", \" have\", sentence)\n",
    "    sentence = re.sub(r\"\\'m\", \" am\", sentence)\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the commoner morphological and inflexional endings from words in English.\n",
    "from nltk.stem import PorterStemmer\n",
    "def stemming(sentence):\n",
    "    ps = PorterStemmer()\n",
    "    article = \"\"\n",
    "    for word in sentence.split():\n",
    "        word = str(word)\n",
    "        article = article + ps.stem(word)+ \" \"\n",
    "    return article.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing words with digits and special characters\n",
    "def Special_char(sentence):\n",
    "    article = \"\"\n",
    "    for word in sentence.split():\n",
    "        word = str(word)\n",
    "        word = re.sub(\"\\S*\\d\\S*\", \"\", word)\n",
    "        word = re.sub('[^A-Za-z0-9]+', \" \", word)\n",
    "        word = word.replace(\" \", \"\")\n",
    "        article = article + word + ' '\n",
    "    return article.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def lemma(phrase):\n",
    "    article = \"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for word in phrase.split():\n",
    "        article += lemmatizer.lemmatize(word) + ' '\n",
    "    return article.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating average word length of the article\n",
    "def get_avg_wordlen(article):\n",
    "    words = article.split()\n",
    "    word_len = 0\n",
    "    if len(words) > 0:  # To avoid zero divisional error\n",
    "        for word in words:\n",
    "            word_len += len(word)\n",
    "    else: \n",
    "        return 0\n",
    "    return word_len/len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove all those articles which does not contain any meaningfull word\n",
    "def drop_noword_article(df):\n",
    "    df.drop(index = list(df[df['article_len']==0].index),inplace = True, axis = 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negation_count(article):\n",
    "    neg_words = ['no', 'not', 'none', 'nothing', 'neither', 'never', 'hardly', 'scarcely', 'barely']\n",
    "    counter = 0\n",
    "    for token in article.split():\n",
    "        if token in neg_words:\n",
    "            counter += 1\n",
    "    return counter        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(df):\n",
    "    df.apply(missing_values)\n",
    "    print(\"Cleaning......\")\n",
    "    df['cleaned_article'] = df['cleaned_article'].str.lower()\n",
    "    df['cleaned_article'] = df['cleaned_article'].progress_apply(Link_removal)\n",
    "    df['cleaned_article'] = df['cleaned_article'].progress_apply(Tag_removal)\n",
    "    df['cleaned_article'] = df['cleaned_article'].progress_apply(Decontracted)\n",
    "    \n",
    "    print(\"Pre-Featurization\")\n",
    "    df = prefeaturization(df)\n",
    "    \n",
    "    print(\"Cleaning......\")\n",
    "    print(\"Special Char\")\n",
    "    df['cleaned_article'] = df['cleaned_article'].progress_apply(Special_char)\n",
    "    \n",
    "    # Computing length on the article\n",
    "    print(\"Article Length\")\n",
    "    df['article_len'] = df['cleaned_article'].progress_apply(lambda x: len(x))\n",
    "    \n",
    "    print(\"Lemmetization\")\n",
    "    df['cleaned_article'] = df['cleaned_article'].progress_apply(lemma)\n",
    "    \n",
    "    # Counting number of negative words used in the article\n",
    "    print(\"Negative Words...\")\n",
    "    df['negations'] = df['cleaned_article'].progress_apply(lambda x: negation_count(x))\n",
    "    \n",
    "    print(\"Preprocessing\")\n",
    "    df['cleaned_article'] = df['cleaned_article'].progress_apply(preprocessing) # Stopwords removal\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "def feature_engineering(df):\n",
    "    \n",
    "    # Calculating polarity score using textblob\n",
    "    print(\"Polarity\")\n",
    "    df['polarity'] = df['cleaned_article'].progress_apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "    \n",
    "    # Counting number of words present in cleaned articles\n",
    "    print(\"Word Count\")\n",
    "    df['word_count'] = df['cleaned_article'].progress_apply(lambda x: len(x.split()))\n",
    "    \n",
    "    # Averge length of each word present in the cleaned article\n",
    "    print(\"Average Word Count\")\n",
    "    df['avg_word_len'] = df['cleaned_article'].progress_apply(lambda x: get_avg_wordlen(x))\n",
    "    \n",
    "    # Counting number of unique words present in the article\n",
    "    print(\"Number of Unique Words\")\n",
    "    df[\"num_unique_words\"] = df[\"cleaned_article\"].progress_apply(lambda x: len(set(str(x).split())))\n",
    "    \n",
    "    # Counting number of characters present in the article\n",
    "    print(\"Number of Chars\")\n",
    "    df[\"num_chars\"] = df[\"cleaned_article\"].progress_apply(lambda x: len(str(x)))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 1   (Train 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3  FBI Russia probe helped by Australian diplomat...   \n",
       "4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
       "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
       "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
       "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
       "\n",
       "                 date  \n",
       "0  December 31, 2017   \n",
       "1  December 29, 2017   \n",
       "2  December 31, 2017   \n",
       "3  December 30, 2017   \n",
       "4  December 29, 2017   "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing dataset\n",
    "df_true = pd.read_csv(\"Training_data/True.csv\")\n",
    "df_fake = pd.read_csv(\"Training_data/Fake.csv\")\n",
    "df_true.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23476</th>\n",
       "      <td>McPain: John McCain Furious That Iran Treated ...</td>\n",
       "      <td>21st Century Wire says As 21WIRE reported earl...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>January 16, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23477</th>\n",
       "      <td>JUSTICE? Yahoo Settles E-mail Privacy Class-ac...</td>\n",
       "      <td>21st Century Wire says It s a familiar theme. ...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>January 16, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23478</th>\n",
       "      <td>Sunnistan: US and Allied ‘Safe Zone’ Plan to T...</td>\n",
       "      <td>Patrick Henningsen  21st Century WireRemember ...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>January 15, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23479</th>\n",
       "      <td>How to Blow $700 Million: Al Jazeera America F...</td>\n",
       "      <td>21st Century Wire says Al Jazeera America will...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>January 14, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23480</th>\n",
       "      <td>10 U.S. Navy Sailors Held by Iranian Military ...</td>\n",
       "      <td>21st Century Wire says As 21WIRE predicted in ...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>January 12, 2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "23476  McPain: John McCain Furious That Iran Treated ...   \n",
       "23477  JUSTICE? Yahoo Settles E-mail Privacy Class-ac...   \n",
       "23478  Sunnistan: US and Allied ‘Safe Zone’ Plan to T...   \n",
       "23479  How to Blow $700 Million: Al Jazeera America F...   \n",
       "23480  10 U.S. Navy Sailors Held by Iranian Military ...   \n",
       "\n",
       "                                                    text      subject  \\\n",
       "23476  21st Century Wire says As 21WIRE reported earl...  Middle-east   \n",
       "23477  21st Century Wire says It s a familiar theme. ...  Middle-east   \n",
       "23478  Patrick Henningsen  21st Century WireRemember ...  Middle-east   \n",
       "23479  21st Century Wire says Al Jazeera America will...  Middle-east   \n",
       "23480  21st Century Wire says As 21WIRE predicted in ...  Middle-east   \n",
       "\n",
       "                   date  \n",
       "23476  January 16, 2016  \n",
       "23477  January 16, 2016  \n",
       "23478  January 15, 2016  \n",
       "23479  January 14, 2016  \n",
       "23480  January 12, 2016  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fake.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labeling real news as 1 and fake news as 0\n",
    "df_true['label'] = 1\n",
    "df_fake['label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44893</th>\n",
       "      <td>McPain: John McCain Furious That Iran Treated ...</td>\n",
       "      <td>21st Century Wire says As 21WIRE reported earl...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>January 16, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44894</th>\n",
       "      <td>JUSTICE? Yahoo Settles E-mail Privacy Class-ac...</td>\n",
       "      <td>21st Century Wire says It s a familiar theme. ...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>January 16, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44895</th>\n",
       "      <td>Sunnistan: US and Allied ‘Safe Zone’ Plan to T...</td>\n",
       "      <td>Patrick Henningsen  21st Century WireRemember ...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>January 15, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44896</th>\n",
       "      <td>How to Blow $700 Million: Al Jazeera America F...</td>\n",
       "      <td>21st Century Wire says Al Jazeera America will...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>January 14, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44897</th>\n",
       "      <td>10 U.S. Navy Sailors Held by Iranian Military ...</td>\n",
       "      <td>21st Century Wire says As 21WIRE predicted in ...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>January 12, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44898 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0      As U.S. budget fight looms, Republicans flip t...   \n",
       "1      U.S. military to accept transgender recruits o...   \n",
       "2      Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3      FBI Russia probe helped by Australian diplomat...   \n",
       "4      Trump wants Postal Service to charge 'much mor...   \n",
       "...                                                  ...   \n",
       "44893  McPain: John McCain Furious That Iran Treated ...   \n",
       "44894  JUSTICE? Yahoo Settles E-mail Privacy Class-ac...   \n",
       "44895  Sunnistan: US and Allied ‘Safe Zone’ Plan to T...   \n",
       "44896  How to Blow $700 Million: Al Jazeera America F...   \n",
       "44897  10 U.S. Navy Sailors Held by Iranian Military ...   \n",
       "\n",
       "                                                    text       subject  \\\n",
       "0      WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "1      WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
       "2      WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
       "3      WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
       "4      SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
       "...                                                  ...           ...   \n",
       "44893  21st Century Wire says As 21WIRE reported earl...   Middle-east   \n",
       "44894  21st Century Wire says It s a familiar theme. ...   Middle-east   \n",
       "44895  Patrick Henningsen  21st Century WireRemember ...   Middle-east   \n",
       "44896  21st Century Wire says Al Jazeera America will...   Middle-east   \n",
       "44897  21st Century Wire says As 21WIRE predicted in ...   Middle-east   \n",
       "\n",
       "                     date  label  \n",
       "0      December 31, 2017       1  \n",
       "1      December 29, 2017       1  \n",
       "2      December 31, 2017       1  \n",
       "3      December 30, 2017       1  \n",
       "4      December 29, 2017       1  \n",
       "...                   ...    ...  \n",
       "44893    January 16, 2016      0  \n",
       "44894    January 16, 2016      0  \n",
       "44895    January 15, 2016      0  \n",
       "44896    January 14, 2016      0  \n",
       "44897    January 12, 2016      0  \n",
       "\n",
       "[44898 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mergeing true and fake dataframe into one dataframe\n",
    "df1 = pd.concat([df_true, df_fake], ignore_index= True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNN Host Tells Senate Republican To Do His Da...</td>\n",
       "      <td>Republican Senator Orrin Hatch tried to justif...</td>\n",
       "      <td>News</td>\n",
       "      <td>February 16, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>At least 19 drown when boat capsizes in northe...</td>\n",
       "      <td>NEW DELHI (Reuters) - At least 19 people drown...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>September 14, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One in five Indonesian students support Islami...</td>\n",
       "      <td>JAKARTA (Reuters) - Nearly 20 percent of high ...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>November 2, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hillary Clinton is ‘Most Corrupt, Militaristic...</td>\n",
       "      <td>21st Century Wire says The writing is on the w...</td>\n",
       "      <td>US_News</td>\n",
       "      <td>May 17, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRUTALLY HONEST BILLBOARD Turns Heads In State...</td>\n",
       "      <td>American citizens should be more concerned abo...</td>\n",
       "      <td>politics</td>\n",
       "      <td>Jul 16, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44893</th>\n",
       "      <td>ILLEGAL ALIEN COLLEGE STUDENTS Protest For A F...</td>\n",
       "      <td>Social Media went nuts when illegal alien coll...</td>\n",
       "      <td>Government News</td>\n",
       "      <td>Sep 17, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44894</th>\n",
       "      <td>HOW PEOPLE MAGAZINE COVER Proves Hillary Has A...</td>\n",
       "      <td>Does anyone else get the sense Hillary is not ...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>Aug 16, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44895</th>\n",
       "      <td>GREAT! PRO-COAL OKLAHOMA AG Tapped For Head Of...</td>\n",
       "      <td>When the Environmental Protection Agency prop...</td>\n",
       "      <td>politics</td>\n",
       "      <td>Dec 7, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44896</th>\n",
       "      <td>U.S. congressional committee subpoenas ex-drug...</td>\n",
       "      <td>WASHINGTON/NEW YORK (Reuters) - A U.S. congres...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>January 20, 2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44897</th>\n",
       "      <td>Protesters throw rocks, bottles at police outs...</td>\n",
       "      <td>(Reuters) - Protesters threw rocks and bottles...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>May 25, 2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44898 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0       CNN Host Tells Senate Republican To Do His Da...   \n",
       "1      At least 19 drown when boat capsizes in northe...   \n",
       "2      One in five Indonesian students support Islami...   \n",
       "3      Hillary Clinton is ‘Most Corrupt, Militaristic...   \n",
       "4      BRUTALLY HONEST BILLBOARD Turns Heads In State...   \n",
       "...                                                  ...   \n",
       "44893  ILLEGAL ALIEN COLLEGE STUDENTS Protest For A F...   \n",
       "44894  HOW PEOPLE MAGAZINE COVER Proves Hillary Has A...   \n",
       "44895  GREAT! PRO-COAL OKLAHOMA AG Tapped For Head Of...   \n",
       "44896  U.S. congressional committee subpoenas ex-drug...   \n",
       "44897  Protesters throw rocks, bottles at police outs...   \n",
       "\n",
       "                                                    text          subject  \\\n",
       "0      Republican Senator Orrin Hatch tried to justif...             News   \n",
       "1      NEW DELHI (Reuters) - At least 19 people drown...        worldnews   \n",
       "2      JAKARTA (Reuters) - Nearly 20 percent of high ...        worldnews   \n",
       "3      21st Century Wire says The writing is on the w...          US_News   \n",
       "4      American citizens should be more concerned abo...         politics   \n",
       "...                                                  ...              ...   \n",
       "44893  Social Media went nuts when illegal alien coll...  Government News   \n",
       "44894  Does anyone else get the sense Hillary is not ...        left-news   \n",
       "44895   When the Environmental Protection Agency prop...         politics   \n",
       "44896  WASHINGTON/NEW YORK (Reuters) - A U.S. congres...     politicsNews   \n",
       "44897  (Reuters) - Protesters threw rocks and bottles...     politicsNews   \n",
       "\n",
       "                      date  label  \n",
       "0        February 16, 2016      0  \n",
       "1      September 14, 2017       1  \n",
       "2        November 2, 2017       1  \n",
       "3             May 17, 2016      0  \n",
       "4             Jul 16, 2016      0  \n",
       "...                    ...    ...  \n",
       "44893         Sep 17, 2016      0  \n",
       "44894         Aug 16, 2016      0  \n",
       "44895          Dec 7, 2016      0  \n",
       "44896    January 20, 2016       1  \n",
       "44897        May 25, 2016       1  \n",
       "\n",
       "[44898 rows x 5 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mixing/Sample the dataset so 0's and 1's are equally spread through out the dataframe and then resetting the index\n",
    "df1 = df1.sample(frac = 1)\n",
    "df1.reset_index(inplace = True, drop = True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(title      0\n",
       " text       0\n",
       " subject    0\n",
       " date       0\n",
       " label      0\n",
       " dtype: int64,\n",
       " title      0\n",
       " text       0\n",
       " subject    0\n",
       " date       0\n",
       " label      0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking dataset has any null value\n",
    "df1.isna().sum(), df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing null values with empty string\n",
    "df1.fillna(\" \", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNN Host Tells Senate Republican To Do His Da...</td>\n",
       "      <td>Republican Senator Orrin Hatch tried to justif...</td>\n",
       "      <td>News</td>\n",
       "      <td>February 16, 2016</td>\n",
       "      <td>0</td>\n",
       "      <td>CNN Host Tells Senate Republican To Do His Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>At least 19 drown when boat capsizes in northe...</td>\n",
       "      <td>NEW DELHI (Reuters) - At least 19 people drown...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>September 14, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>At least 19 drown when boat capsizes in northe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   CNN Host Tells Senate Republican To Do His Da...   \n",
       "1  At least 19 drown when boat capsizes in northe...   \n",
       "\n",
       "                                                text    subject  \\\n",
       "0  Republican Senator Orrin Hatch tried to justif...       News   \n",
       "1  NEW DELHI (Reuters) - At least 19 people drown...  worldnews   \n",
       "\n",
       "                  date  label  \\\n",
       "0    February 16, 2016      0   \n",
       "1  September 14, 2017       1   \n",
       "\n",
       "                                     cleaned_article  \n",
       "0   CNN Host Tells Senate Republican To Do His Da...  \n",
       "1  At least 19 drown when boat capsizes in northe...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining title and text into one column\n",
    "df1['cleaned_article'] = df1['title'] + \" \" + df1['text']\n",
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>CNN Host Tells Senate Republican To Do His Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>At least 19 drown when boat capsizes in northe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                    cleaned_article\n",
       "0      0   CNN Host Tells Senate Republican To Do His Da...\n",
       "1      1  At least 19 drown when boat capsizes in northe..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Except cleaned_article and label dropping all other columns from data frame.\n",
    "df1.drop(['title', 'text', 'subject', 'date'], axis = 1, inplace = True)\n",
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8caf398ebf414ef5a0ddedf9a9095683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0975ab002d4c45078f8a1196712d2372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9b7479cf4444feb88335a3b16e030e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Featurization\n",
      "Number of punctuations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b752372310544b74b0736d5db813d700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Stopwords\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "521fe0bd4b1f47dd962db924d2266e33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of question marks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db44b54911d149d3a94f8fa6953cda1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Exclamation Marks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "400331502a3649fe9eb33a10742f05d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Sentences\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59ba0c7a860a4978a575135c1a2cb878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d2511ec1b5b4500a7cec3cf16539469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS TAGGING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 44898/44898 [13:05<00:00, 57.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning......\n",
      "Special Char\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "505450c5455a4b7d9625a95ff469566d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article Length\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1504158e42c4776bf10a954e6a1541c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmetization\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f33f9ed841534888a8f5b95e62d08951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Words...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64ba3a9e89c84156a57549f37abfdf65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "109513922205493abc396b7bc042d97e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_article</th>\n",
       "      <th>num_punctuations</th>\n",
       "      <th>no_of_stopwords</th>\n",
       "      <th>no_of_quesMarks</th>\n",
       "      <th>no_of_exclamation</th>\n",
       "      <th>no_of_sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cc_cd</th>\n",
       "      <th>determiner</th>\n",
       "      <th>foreign_w</th>\n",
       "      <th>conj_prep</th>\n",
       "      <th>adjective</th>\n",
       "      <th>modal</th>\n",
       "      <th>noun</th>\n",
       "      <th>adverb</th>\n",
       "      <th>verb</th>\n",
       "      <th>article_len</th>\n",
       "      <th>negations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>host tell senate republican damn video republi...</td>\n",
       "      <td>84</td>\n",
       "      <td>630</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>Negative</td>\n",
       "      <td>27</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>83</td>\n",
       "      <td>12</td>\n",
       "      <td>247</td>\n",
       "      <td>46</td>\n",
       "      <td>196</td>\n",
       "      <td>5166</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>drown boat capsizes northern india police delh...</td>\n",
       "      <td>19</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Negative</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>718</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                    cleaned_article  num_punctuations  \\\n",
       "0      0  host tell senate republican damn video republi...                84   \n",
       "1      1  drown boat capsizes northern india police delh...                19   \n",
       "\n",
       "   no_of_stopwords  no_of_quesMarks  no_of_exclamation  no_of_sentence  \\\n",
       "0              630                2                  0              36   \n",
       "1              112                0                  0               5   \n",
       "\n",
       "  sentiment  cc_cd  determiner  foreign_w  conj_prep  adjective  modal  noun  \\\n",
       "0  Negative     27         101          0        108         83     12   247   \n",
       "1  Negative      8          10          0         15         20      0    35   \n",
       "\n",
       "   adverb  verb  article_len  negations  \n",
       "0      46   196         5166         11  \n",
       "1       2    26          718          1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performing data cleaning and pre-featurization \n",
    "df1 = data_cleaning(df1)\n",
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_article</th>\n",
       "      <th>num_punctuations</th>\n",
       "      <th>no_of_stopwords</th>\n",
       "      <th>no_of_quesMarks</th>\n",
       "      <th>no_of_exclamation</th>\n",
       "      <th>no_of_sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cc_cd</th>\n",
       "      <th>determiner</th>\n",
       "      <th>foreign_w</th>\n",
       "      <th>conj_prep</th>\n",
       "      <th>adjective</th>\n",
       "      <th>modal</th>\n",
       "      <th>noun</th>\n",
       "      <th>adverb</th>\n",
       "      <th>verb</th>\n",
       "      <th>article_len</th>\n",
       "      <th>negations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>host tell senate republican damn video republi...</td>\n",
       "      <td>84</td>\n",
       "      <td>630</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>Negative</td>\n",
       "      <td>27</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>83</td>\n",
       "      <td>12</td>\n",
       "      <td>247</td>\n",
       "      <td>46</td>\n",
       "      <td>196</td>\n",
       "      <td>5166</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>drown boat capsizes northern india police delh...</td>\n",
       "      <td>19</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Negative</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>718</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>indonesian student support islamic caliphate s...</td>\n",
       "      <td>54</td>\n",
       "      <td>456</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>Positive</td>\n",
       "      <td>23</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>144</td>\n",
       "      <td>14</td>\n",
       "      <td>74</td>\n",
       "      <td>2971</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>hillary clinton corrupt militaristic candidate...</td>\n",
       "      <td>9</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>brutally honest billboard turn head state expl...</td>\n",
       "      <td>34</td>\n",
       "      <td>286</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>Negative</td>\n",
       "      <td>7</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>12</td>\n",
       "      <td>49</td>\n",
       "      <td>2049</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44893</th>\n",
       "      <td>0</td>\n",
       "      <td>illegal alien college student protest freebie ...</td>\n",
       "      <td>20</td>\n",
       "      <td>116</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>Positive</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>953</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44894</th>\n",
       "      <td>0</td>\n",
       "      <td>people magazine cover prof hillary wildly unpo...</td>\n",
       "      <td>25</td>\n",
       "      <td>193</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>Positive</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>73</td>\n",
       "      <td>14</td>\n",
       "      <td>42</td>\n",
       "      <td>1517</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44895</th>\n",
       "      <td>0</td>\n",
       "      <td>great procoal oklahoma tapped head environment...</td>\n",
       "      <td>32</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>Positive</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>1318</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44896</th>\n",
       "      <td>1</td>\n",
       "      <td>congressional committee subpoena exdrug shkrel...</td>\n",
       "      <td>66</td>\n",
       "      <td>365</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>Negative</td>\n",
       "      <td>9</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>55</td>\n",
       "      <td>4</td>\n",
       "      <td>130</td>\n",
       "      <td>13</td>\n",
       "      <td>77</td>\n",
       "      <td>2648</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44897</th>\n",
       "      <td>1</td>\n",
       "      <td>protester throw rock bottle police outside tru...</td>\n",
       "      <td>38</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>Negative</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>7</td>\n",
       "      <td>51</td>\n",
       "      <td>1896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44898 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                    cleaned_article  \\\n",
       "0          0  host tell senate republican damn video republi...   \n",
       "1          1  drown boat capsizes northern india police delh...   \n",
       "2          1  indonesian student support islamic caliphate s...   \n",
       "3          0  hillary clinton corrupt militaristic candidate...   \n",
       "4          0  brutally honest billboard turn head state expl...   \n",
       "...      ...                                                ...   \n",
       "44893      0  illegal alien college student protest freebie ...   \n",
       "44894      0  people magazine cover prof hillary wildly unpo...   \n",
       "44895      0  great procoal oklahoma tapped head environment...   \n",
       "44896      1  congressional committee subpoena exdrug shkrel...   \n",
       "44897      1  protester throw rock bottle police outside tru...   \n",
       "\n",
       "       num_punctuations  no_of_stopwords  no_of_quesMarks  no_of_exclamation  \\\n",
       "0                    84              630                2                  0   \n",
       "1                    19              112                0                  0   \n",
       "2                    54              456                0                  0   \n",
       "3                     9               78                0                  0   \n",
       "4                    34              286                1                  0   \n",
       "...                 ...              ...              ...                ...   \n",
       "44893                20              116                2                  1   \n",
       "44894                25              193                3                  0   \n",
       "44895                32              190                0                  1   \n",
       "44896                66              365                1                  0   \n",
       "44897                38              241                0                  0   \n",
       "\n",
       "       no_of_sentence sentiment  cc_cd  determiner  foreign_w  conj_prep  \\\n",
       "0                  36  Negative     27         101          0        108   \n",
       "1                   5  Negative      8          10          0         15   \n",
       "2                  20  Positive     23          45          0         64   \n",
       "3                   2  Positive      3          11          0         10   \n",
       "4                  11  Negative      7          45          0         47   \n",
       "...               ...       ...    ...         ...        ...        ...   \n",
       "44893              10  Positive      4          10          0         21   \n",
       "44894               6  Positive     12          21          0         35   \n",
       "44895              10  Positive      8          17          0         23   \n",
       "44896              17  Negative      9          37          1         59   \n",
       "44897              14  Negative     13          20          0         44   \n",
       "\n",
       "       adjective  modal  noun  adverb  verb  article_len  negations  \n",
       "0             83     12   247      46   196         5166         11  \n",
       "1             20      0    35       2    26          718          1  \n",
       "2             62      2   144      14    74         2971          0  \n",
       "3             17      1    30       1    17          560          0  \n",
       "4             27      4   120      12    49         2049          1  \n",
       "...          ...    ...   ...     ...   ...          ...        ...  \n",
       "44893         22      2    45       5    31          953          0  \n",
       "44894         34      5    73      14    42         1517          3  \n",
       "44895         26      0    80       5    32         1318          0  \n",
       "44896         55      4   130      13    77         2648          1  \n",
       "44897         34      0   110       7    51         1896          1  \n",
       "\n",
       "[44898 rows x 19 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba1005156474716b16d2b4183024026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Count\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95b1ea736c1a443c9ab56d9d2e408f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Word Count\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e1712f5bcf44191aa7e5ed128595cf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique Words\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dbb533a6fb542a78d41e7e454d4385a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Chars\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9226225b94794f70911db71d6355bb3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_article</th>\n",
       "      <th>num_punctuations</th>\n",
       "      <th>no_of_stopwords</th>\n",
       "      <th>no_of_quesMarks</th>\n",
       "      <th>no_of_exclamation</th>\n",
       "      <th>no_of_sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cc_cd</th>\n",
       "      <th>determiner</th>\n",
       "      <th>...</th>\n",
       "      <th>noun</th>\n",
       "      <th>adverb</th>\n",
       "      <th>verb</th>\n",
       "      <th>article_len</th>\n",
       "      <th>negations</th>\n",
       "      <th>polarity</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>num_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>host tell senate republican damn video republi...</td>\n",
       "      <td>84</td>\n",
       "      <td>630</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>Negative</td>\n",
       "      <td>27</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>247</td>\n",
       "      <td>46</td>\n",
       "      <td>196</td>\n",
       "      <td>5166</td>\n",
       "      <td>11</td>\n",
       "      <td>0.165890</td>\n",
       "      <td>371</td>\n",
       "      <td>6.636119</td>\n",
       "      <td>223</td>\n",
       "      <td>2832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>drown boat capsizes northern india police delh...</td>\n",
       "      <td>19</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Negative</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>718</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.150000</td>\n",
       "      <td>62</td>\n",
       "      <td>6.532258</td>\n",
       "      <td>44</td>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>indonesian student support islamic caliphate s...</td>\n",
       "      <td>54</td>\n",
       "      <td>456</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>Positive</td>\n",
       "      <td>23</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>14</td>\n",
       "      <td>74</td>\n",
       "      <td>2971</td>\n",
       "      <td>0</td>\n",
       "      <td>0.038395</td>\n",
       "      <td>250</td>\n",
       "      <td>7.428000</td>\n",
       "      <td>171</td>\n",
       "      <td>2106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>hillary clinton corrupt militaristic candidate...</td>\n",
       "      <td>9</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>560</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022159</td>\n",
       "      <td>51</td>\n",
       "      <td>6.725490</td>\n",
       "      <td>37</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>brutally honest billboard turn head state expl...</td>\n",
       "      <td>34</td>\n",
       "      <td>286</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>Negative</td>\n",
       "      <td>7</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>120</td>\n",
       "      <td>12</td>\n",
       "      <td>49</td>\n",
       "      <td>2049</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015278</td>\n",
       "      <td>174</td>\n",
       "      <td>7.155172</td>\n",
       "      <td>123</td>\n",
       "      <td>1418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44893</th>\n",
       "      <td>0</td>\n",
       "      <td>illegal alien college student protest freebie ...</td>\n",
       "      <td>20</td>\n",
       "      <td>116</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>Positive</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>953</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.015278</td>\n",
       "      <td>73</td>\n",
       "      <td>6.726027</td>\n",
       "      <td>60</td>\n",
       "      <td>563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44894</th>\n",
       "      <td>0</td>\n",
       "      <td>people magazine cover prof hillary wildly unpo...</td>\n",
       "      <td>25</td>\n",
       "      <td>193</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>Positive</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>73</td>\n",
       "      <td>14</td>\n",
       "      <td>42</td>\n",
       "      <td>1517</td>\n",
       "      <td>3</td>\n",
       "      <td>0.099242</td>\n",
       "      <td>126</td>\n",
       "      <td>6.992063</td>\n",
       "      <td>92</td>\n",
       "      <td>1006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44895</th>\n",
       "      <td>0</td>\n",
       "      <td>great procoal oklahoma tapped head environment...</td>\n",
       "      <td>32</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>Positive</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>1318</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>111</td>\n",
       "      <td>7.135135</td>\n",
       "      <td>84</td>\n",
       "      <td>902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44896</th>\n",
       "      <td>1</td>\n",
       "      <td>congressional committee subpoena exdrug shkrel...</td>\n",
       "      <td>66</td>\n",
       "      <td>365</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>Negative</td>\n",
       "      <td>9</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>13</td>\n",
       "      <td>77</td>\n",
       "      <td>2648</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.158543</td>\n",
       "      <td>211</td>\n",
       "      <td>7.374408</td>\n",
       "      <td>151</td>\n",
       "      <td>1766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44897</th>\n",
       "      <td>1</td>\n",
       "      <td>protester throw rock bottle police outside tru...</td>\n",
       "      <td>38</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>Negative</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>110</td>\n",
       "      <td>7</td>\n",
       "      <td>51</td>\n",
       "      <td>1896</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.075347</td>\n",
       "      <td>169</td>\n",
       "      <td>6.775148</td>\n",
       "      <td>114</td>\n",
       "      <td>1313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44898 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                    cleaned_article  \\\n",
       "0          0  host tell senate republican damn video republi...   \n",
       "1          1  drown boat capsizes northern india police delh...   \n",
       "2          1  indonesian student support islamic caliphate s...   \n",
       "3          0  hillary clinton corrupt militaristic candidate...   \n",
       "4          0  brutally honest billboard turn head state expl...   \n",
       "...      ...                                                ...   \n",
       "44893      0  illegal alien college student protest freebie ...   \n",
       "44894      0  people magazine cover prof hillary wildly unpo...   \n",
       "44895      0  great procoal oklahoma tapped head environment...   \n",
       "44896      1  congressional committee subpoena exdrug shkrel...   \n",
       "44897      1  protester throw rock bottle police outside tru...   \n",
       "\n",
       "       num_punctuations  no_of_stopwords  no_of_quesMarks  no_of_exclamation  \\\n",
       "0                    84              630                2                  0   \n",
       "1                    19              112                0                  0   \n",
       "2                    54              456                0                  0   \n",
       "3                     9               78                0                  0   \n",
       "4                    34              286                1                  0   \n",
       "...                 ...              ...              ...                ...   \n",
       "44893                20              116                2                  1   \n",
       "44894                25              193                3                  0   \n",
       "44895                32              190                0                  1   \n",
       "44896                66              365                1                  0   \n",
       "44897                38              241                0                  0   \n",
       "\n",
       "       no_of_sentence sentiment  cc_cd  determiner  ...  noun  adverb  verb  \\\n",
       "0                  36  Negative     27         101  ...   247      46   196   \n",
       "1                   5  Negative      8          10  ...    35       2    26   \n",
       "2                  20  Positive     23          45  ...   144      14    74   \n",
       "3                   2  Positive      3          11  ...    30       1    17   \n",
       "4                  11  Negative      7          45  ...   120      12    49   \n",
       "...               ...       ...    ...         ...  ...   ...     ...   ...   \n",
       "44893              10  Positive      4          10  ...    45       5    31   \n",
       "44894               6  Positive     12          21  ...    73      14    42   \n",
       "44895              10  Positive      8          17  ...    80       5    32   \n",
       "44896              17  Negative      9          37  ...   130      13    77   \n",
       "44897              14  Negative     13          20  ...   110       7    51   \n",
       "\n",
       "       article_len  negations  polarity  word_count  avg_word_len  \\\n",
       "0             5166         11  0.165890         371      6.636119   \n",
       "1              718          1 -0.150000          62      6.532258   \n",
       "2             2971          0  0.038395         250      7.428000   \n",
       "3              560          0  0.022159          51      6.725490   \n",
       "4             2049          1  0.015278         174      7.155172   \n",
       "...            ...        ...       ...         ...           ...   \n",
       "44893          953          0 -0.015278          73      6.726027   \n",
       "44894         1517          3  0.099242         126      6.992063   \n",
       "44895         1318          0  0.142857         111      7.135135   \n",
       "44896         2648          1 -0.158543         211      7.374408   \n",
       "44897         1896          1 -0.075347         169      6.775148   \n",
       "\n",
       "       num_unique_words  num_chars  \n",
       "0                   223       2832  \n",
       "1                    44        466  \n",
       "2                   171       2106  \n",
       "3                    37        393  \n",
       "4                   123       1418  \n",
       "...                 ...        ...  \n",
       "44893                60        563  \n",
       "44894                92       1006  \n",
       "44895                84        902  \n",
       "44896               151       1766  \n",
       "44897               114       1313  \n",
       "\n",
       "[44898 rows x 24 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating features after data cleaning\n",
    "feature_engineering(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There were few rows in article which has only blank space and no words. Therefore, we are dropping those rows\n",
    "#drop_noword_article(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1[df1['article_len']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'host tell senate republican damn video republican senator orrin hatch tried justify chris cuomo itduring appearance tuesday senate judiciary committee member orrin hatch attempted defend decision senate republican refuse hold confirmation hearing president obama nominates vacant seat justice antonin scalia passed away saturdayever news broke scalia death republican clear allow president obama position bench opting instead wait year whomever elected president november office hope republicanbut host chris cuomo told hatch colleague damn constitution requires especially document conservative claim love president able pick judicial nominee election year vote judge election year final year presidency hypocrisy play cuomo bluntly like nominates process course like good little obstructionist hatch continued insist republican think real reason cuomo asked constitution hatch responded claiming president obama treated fairly senate republican know crock shit considering record obstructing president obama took office seven year response hatch revealed real reason republican want wait replace scalia look president treated fairly percent federal judiciary republican allowed vote saying look tremendous presidential campaign bitterness diffuse thing president united state wait discretion president democrat course naturally want want majority court interview hatch claimed democrat muddied confirming conservative extremist robert bork high court cuomo pointed democrat held confirmation hearing required constitution went process bork confirmed senate right senate power reject nominee appears hatch fellow republican case sour grape democrat turned anthony kennedy ended confirmed supreme court instead borkthe line senate democrat went process eventually rejected bork fact republican voted bork wellcuomo informed hatch court good thing case settled constant delay real decision case pile unresolved case refiled argued hatch think court good thing court function functioned past function time controversial issue probably year world matter fact smart thing multiple time interview hatch brought presidential election unfair hold hearing time cuomo mentioned constitution confirming judge election year hatch claimed constitution right defer sure best opportunity person presidency know democrat process ought gone video youtubeagain hatch bullshit claim know republican control senate continue throw temper tantrum refuse hillary clinton bernie sander president nomination word thing different right nowhatch senate republican reason government country threatening derail judicial break precedent want supreme court shift away extreme conservative ideology controlled court decade totally outrageous american people need punish republican failure normal american worker failed fired senate republican featured image story'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['cleaned_article'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"Cleaned/cleaned_data_1.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similar steps has been performed on other 4 datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 2    (Train 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title           author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...    Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...  Daniel J. Flynn   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"Training_data/train.csv\")\n",
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As per the source in this dataset label 1 indicate news in unrelible means fake on the other hand 0 indicate relible means real new.\n",
    "# 0 -> Real and 1 -> Fake\n",
    "# Here I am converting label as per our problem statement.  0-> Fake and 1 -> Real\n",
    "\n",
    "df2.label.replace({0:1, 1:0}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10413\n",
       "1    10387\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20800 entries, 0 to 20799\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      20800 non-null  int64 \n",
      " 1   title   20242 non-null  object\n",
      " 2   author  18843 non-null  object\n",
      " 3   text    20761 non-null  object\n",
      " 4   label   20800 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 812.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.fillna(\" \",inplace = True)\n",
    "df2['cleaned_article'] = df2['title'] + \" \" + df2['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['cleaned_article'].isna().sum(), df2['cleaned_article'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.dropna(inplace = True)\n",
    "df2.drop(['id', 'author', 'title', 'text'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Why the Truth Might Get You Fired Why the Trut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                    cleaned_article\n",
       "0      0  House Dem Aide: We Didn’t Even See Comey’s Let...\n",
       "1      1  FLYNN: Hillary Clinton, Big Woman on Campus - ...\n",
       "2      0  Why the Truth Might Get You Fired Why the Trut...\n",
       "3      0  15 Civilians Killed In Single US Airstrike Hav...\n",
       "4      0  Iranian woman jailed for fictional unpublished..."
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c963c2ffc1d452081f3bcd66d3cdcf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "397217db01e44e6cb8dd639efd15fca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3578a292b4444b2fbd23378cda0a3180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Featurization\n",
      "Number of punctuations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a305cb18f264fc49e9fc0f99dc1265f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Stopwords\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc799c73713c4af5b257bdd53949dfac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of question marks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "877821c164ce42b090d52c4a6373e0b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Exclamation Marks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a43f7bacc30b43ea8e8b875d1376b907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Sentences\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66898dbb39044c12b7b0db95cd5f93be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c9aaa068f8d4bb997a8f2e292b32a43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS TAGGING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 20800/20800 [11:52<00:00, 29.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning......\n",
      "Special Char\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "324147444f874f70a435ac69646a348f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article Length\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11329bf8550447ba9dc190e5aebee5ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmetization\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b78112a8063411c91d1a1a70d1fce4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Words...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c09eee1a63fb46a1a8e1b15069f015de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ea5b03e795841789e675a237a0e7202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_article</th>\n",
       "      <th>num_punctuations</th>\n",
       "      <th>no_of_stopwords</th>\n",
       "      <th>no_of_quesMarks</th>\n",
       "      <th>no_of_exclamation</th>\n",
       "      <th>no_of_sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cc_cd</th>\n",
       "      <th>determiner</th>\n",
       "      <th>foreign_w</th>\n",
       "      <th>conj_prep</th>\n",
       "      <th>adjective</th>\n",
       "      <th>modal</th>\n",
       "      <th>noun</th>\n",
       "      <th>adverb</th>\n",
       "      <th>verb</th>\n",
       "      <th>article_len</th>\n",
       "      <th>negations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>house aide didnt comeys letter jason chaffetz ...</td>\n",
       "      <td>88</td>\n",
       "      <td>635</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>Positive</td>\n",
       "      <td>30</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>87</td>\n",
       "      <td>5</td>\n",
       "      <td>229</td>\n",
       "      <td>44</td>\n",
       "      <td>155</td>\n",
       "      <td>4848</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>flynn hillary clinton woman campus breitbart f...</td>\n",
       "      <td>77</td>\n",
       "      <td>504</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>Negative</td>\n",
       "      <td>31</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>78</td>\n",
       "      <td>5</td>\n",
       "      <td>185</td>\n",
       "      <td>39</td>\n",
       "      <td>108</td>\n",
       "      <td>4045</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                    cleaned_article  num_punctuations  \\\n",
       "0      0  house aide didnt comeys letter jason chaffetz ...                88   \n",
       "1      1  flynn hillary clinton woman campus breitbart f...                77   \n",
       "\n",
       "   no_of_stopwords  no_of_quesMarks  no_of_exclamation  no_of_sentence  \\\n",
       "0              635                0                  0              36   \n",
       "1              504                4                  0              29   \n",
       "\n",
       "  sentiment  cc_cd  determiner  foreign_w  conj_prep  adjective  modal  noun  \\\n",
       "0  Positive     30          76          0        111         87      5   229   \n",
       "1  Negative     31          73          0        107         78      5   185   \n",
       "\n",
       "   adverb  verb  article_len  negations  \n",
       "0      44   155         4848          7  \n",
       "1      39   108         4045          5  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = data_cleaning(df2)\n",
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "417c883ac65c4b62bfaec64fff85e221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Count\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e635f51bf19e41c1a9fb08bc77286a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Word Count\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26addf5d46534674b96bd4ad8a8cec72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique Words\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb0cbaf3e824a8e8524ca4c2d344b52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Chars\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb9bf6534a2e462194ae816eebcbd61d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_article</th>\n",
       "      <th>num_punctuations</th>\n",
       "      <th>no_of_stopwords</th>\n",
       "      <th>no_of_quesMarks</th>\n",
       "      <th>no_of_exclamation</th>\n",
       "      <th>no_of_sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cc_cd</th>\n",
       "      <th>determiner</th>\n",
       "      <th>...</th>\n",
       "      <th>noun</th>\n",
       "      <th>adverb</th>\n",
       "      <th>verb</th>\n",
       "      <th>article_len</th>\n",
       "      <th>negations</th>\n",
       "      <th>polarity</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>num_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>house aide didnt comeys letter jason chaffetz ...</td>\n",
       "      <td>88</td>\n",
       "      <td>635</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>Positive</td>\n",
       "      <td>30</td>\n",
       "      <td>76</td>\n",
       "      <td>...</td>\n",
       "      <td>229</td>\n",
       "      <td>44</td>\n",
       "      <td>155</td>\n",
       "      <td>4848</td>\n",
       "      <td>7</td>\n",
       "      <td>0.024100</td>\n",
       "      <td>381</td>\n",
       "      <td>6.874016</td>\n",
       "      <td>235</td>\n",
       "      <td>2999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>flynn hillary clinton woman campus breitbart f...</td>\n",
       "      <td>77</td>\n",
       "      <td>504</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>Negative</td>\n",
       "      <td>31</td>\n",
       "      <td>73</td>\n",
       "      <td>...</td>\n",
       "      <td>185</td>\n",
       "      <td>39</td>\n",
       "      <td>108</td>\n",
       "      <td>4045</td>\n",
       "      <td>5</td>\n",
       "      <td>0.049707</td>\n",
       "      <td>314</td>\n",
       "      <td>6.777070</td>\n",
       "      <td>242</td>\n",
       "      <td>2441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>truth fired truth fired october tension intell...</td>\n",
       "      <td>184</td>\n",
       "      <td>1023</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>Positive</td>\n",
       "      <td>46</td>\n",
       "      <td>134</td>\n",
       "      <td>...</td>\n",
       "      <td>347</td>\n",
       "      <td>69</td>\n",
       "      <td>218</td>\n",
       "      <td>7450</td>\n",
       "      <td>15</td>\n",
       "      <td>0.093199</td>\n",
       "      <td>576</td>\n",
       "      <td>6.925347</td>\n",
       "      <td>390</td>\n",
       "      <td>4564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>civilian killed single airstrike identified vi...</td>\n",
       "      <td>51</td>\n",
       "      <td>521</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>Negative</td>\n",
       "      <td>33</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>138</td>\n",
       "      <td>16</td>\n",
       "      <td>119</td>\n",
       "      <td>3191</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.001918</td>\n",
       "      <td>244</td>\n",
       "      <td>6.905738</td>\n",
       "      <td>146</td>\n",
       "      <td>1928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>iranian woman jailed fictional unpublished sto...</td>\n",
       "      <td>16</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Negative</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>992</td>\n",
       "      <td>2</td>\n",
       "      <td>0.039286</td>\n",
       "      <td>87</td>\n",
       "      <td>6.816092</td>\n",
       "      <td>61</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20795</th>\n",
       "      <td>1</td>\n",
       "      <td>rapper trump poster child white supremacy rapp...</td>\n",
       "      <td>48</td>\n",
       "      <td>227</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>Positive</td>\n",
       "      <td>14</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>114</td>\n",
       "      <td>6</td>\n",
       "      <td>59</td>\n",
       "      <td>1780</td>\n",
       "      <td>0</td>\n",
       "      <td>0.069643</td>\n",
       "      <td>151</td>\n",
       "      <td>6.503311</td>\n",
       "      <td>120</td>\n",
       "      <td>1132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20796</th>\n",
       "      <td>1</td>\n",
       "      <td>playoff schedule matchup odds york time green ...</td>\n",
       "      <td>186</td>\n",
       "      <td>720</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>Positive</td>\n",
       "      <td>65</td>\n",
       "      <td>170</td>\n",
       "      <td>...</td>\n",
       "      <td>371</td>\n",
       "      <td>26</td>\n",
       "      <td>156</td>\n",
       "      <td>5807</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.055288</td>\n",
       "      <td>452</td>\n",
       "      <td>6.103982</td>\n",
       "      <td>247</td>\n",
       "      <td>3210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20797</th>\n",
       "      <td>1</td>\n",
       "      <td>macys receive takeover approach hudson york ti...</td>\n",
       "      <td>108</td>\n",
       "      <td>636</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>Positive</td>\n",
       "      <td>46</td>\n",
       "      <td>79</td>\n",
       "      <td>...</td>\n",
       "      <td>257</td>\n",
       "      <td>32</td>\n",
       "      <td>151</td>\n",
       "      <td>4668</td>\n",
       "      <td>5</td>\n",
       "      <td>0.104762</td>\n",
       "      <td>396</td>\n",
       "      <td>6.537879</td>\n",
       "      <td>259</td>\n",
       "      <td>2984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20798</th>\n",
       "      <td>0</td>\n",
       "      <td>nato russia hold parallel exercise balkan nato...</td>\n",
       "      <td>33</td>\n",
       "      <td>268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>28</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>91</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>1738</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.035973</td>\n",
       "      <td>155</td>\n",
       "      <td>7.083871</td>\n",
       "      <td>99</td>\n",
       "      <td>1252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20799</th>\n",
       "      <td>0</td>\n",
       "      <td>alive david swanson author activist journalist...</td>\n",
       "      <td>287</td>\n",
       "      <td>954</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>Negative</td>\n",
       "      <td>69</td>\n",
       "      <td>104</td>\n",
       "      <td>...</td>\n",
       "      <td>387</td>\n",
       "      <td>36</td>\n",
       "      <td>178</td>\n",
       "      <td>6611</td>\n",
       "      <td>4</td>\n",
       "      <td>0.063004</td>\n",
       "      <td>548</td>\n",
       "      <td>6.972628</td>\n",
       "      <td>395</td>\n",
       "      <td>4368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20800 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                    cleaned_article  \\\n",
       "0          0  house aide didnt comeys letter jason chaffetz ...   \n",
       "1          1  flynn hillary clinton woman campus breitbart f...   \n",
       "2          0  truth fired truth fired october tension intell...   \n",
       "3          0  civilian killed single airstrike identified vi...   \n",
       "4          0  iranian woman jailed fictional unpublished sto...   \n",
       "...      ...                                                ...   \n",
       "20795      1  rapper trump poster child white supremacy rapp...   \n",
       "20796      1  playoff schedule matchup odds york time green ...   \n",
       "20797      1  macys receive takeover approach hudson york ti...   \n",
       "20798      0  nato russia hold parallel exercise balkan nato...   \n",
       "20799      0  alive david swanson author activist journalist...   \n",
       "\n",
       "       num_punctuations  no_of_stopwords  no_of_quesMarks  no_of_exclamation  \\\n",
       "0                    88              635                0                  0   \n",
       "1                    77              504                4                  0   \n",
       "2                   184             1023                4                  0   \n",
       "3                    51              521                0                  0   \n",
       "4                    16              148                0                  0   \n",
       "...                 ...              ...              ...                ...   \n",
       "20795                48              227                2                  0   \n",
       "20796               186              720                0                  0   \n",
       "20797               108              636                0                  0   \n",
       "20798                33              268                0                  0   \n",
       "20799               287              954                7                  0   \n",
       "\n",
       "       no_of_sentence sentiment  cc_cd  determiner  ...  noun  adverb  verb  \\\n",
       "0                  36  Positive     30          76  ...   229      44   155   \n",
       "1                  29  Negative     31          73  ...   185      39   108   \n",
       "2                  50  Positive     46         134  ...   347      69   218   \n",
       "3                  26  Negative     33          67  ...   138      16   119   \n",
       "4                   5  Negative      6          19  ...    53       2    36   \n",
       "...               ...       ...    ...         ...  ...   ...     ...   ...   \n",
       "20795              12  Positive     14          32  ...   114       6    59   \n",
       "20796              49  Positive     65         170  ...   371      26   156   \n",
       "20797              41  Positive     46          79  ...   257      32   151   \n",
       "20798              14   Neutral     28          18  ...    91       2    43   \n",
       "20799              55  Negative     69         104  ...   387      36   178   \n",
       "\n",
       "       article_len  negations  polarity  word_count  avg_word_len  \\\n",
       "0             4848          7  0.024100         381      6.874016   \n",
       "1             4045          5  0.049707         314      6.777070   \n",
       "2             7450         15  0.093199         576      6.925347   \n",
       "3             3191          4 -0.001918         244      6.905738   \n",
       "4              992          2  0.039286          87      6.816092   \n",
       "...            ...        ...       ...         ...           ...   \n",
       "20795         1780          0  0.069643         151      6.503311   \n",
       "20796         5807         19 -0.055288         452      6.103982   \n",
       "20797         4668          5  0.104762         396      6.537879   \n",
       "20798         1738          1 -0.035973         155      7.083871   \n",
       "20799         6611          4  0.063004         548      6.972628   \n",
       "\n",
       "       num_unique_words  num_chars  \n",
       "0                   235       2999  \n",
       "1                   242       2441  \n",
       "2                   390       4564  \n",
       "3                   146       1928  \n",
       "4                    61        679  \n",
       "...                 ...        ...  \n",
       "20795               120       1132  \n",
       "20796               247       3210  \n",
       "20797               259       2984  \n",
       "20798                99       1252  \n",
       "20799               395       4368  \n",
       "\n",
       "[20800 rows x 24 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_engineering(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop_noword_article(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"Cleaned/cleaned_data_2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 3    (Train 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a news release</td>\n",
       "      <td>federation-american-immigration-reform</td>\n",
       "      <td>Unemployment has been on the rise throughout W...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Black Turnout Soft in Early Voting, Boding Ill...</td>\n",
       "      <td>Henry Wolff</td>\n",
       "      <td>Black Turnout Soft in Early Voting, Boding Ill...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                                     a news release   \n",
       "1  Black Turnout Soft in Early Voting, Boding Ill...   \n",
       "\n",
       "                                   author  \\\n",
       "0  federation-american-immigration-reform   \n",
       "1                             Henry Wolff   \n",
       "\n",
       "                                                text  label  \n",
       "0  Unemployment has been on the rise throughout W...      1  \n",
       "1  Black Turnout Soft in Early Voting, Boding Ill...      1  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.read_csv(\"Training_data/full_dataset.csv\")\n",
    "df3.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As per source label 1 represent fake whereas label 0 represents Real news\n",
    "# Converting 0 to 1 and 1 to 0 as per our problem definition \n",
    "df3.label.replace({0:1, 1:0}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    16085\n",
       "0    14853\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title      558\n",
       "author    1957\n",
       "text        39\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.fillna(' ', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['cleaned_article'] = df3['title'] + \" \" + df3['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.drop(['title', 'author', 'text'], axis = 1 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3689b8f1df7d401f87711ffb88fed7d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7738ec8dd6d044739d64c8fbd7219673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ddb8ed06914407944ad6ee3af54d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Featurization\n",
      "Number of punctuations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca55cdbc87894919a39dc596f872ebd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Stopwords\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89d516a27efb40ecaed3d9e5f7cafa57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of question marks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76374df712f444a3be9e7ccf03137eac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Exclamation Marks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37490913965c47fcb837935882a9e82a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Sentences\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "420e8ed9ff24446b8d665dddcd7d2ce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf3ced621bfb4806bc658b87250fede7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS TAGGING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30938/30938 [10:56<00:00, 47.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning......\n",
      "Special Char\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89a37be5570943c3aeca1033d4b4a59d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article Length\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e4d7e6b164045509ddad8a96ed5de34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmetization\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a8a0ea862af45fbbb9c728ea7a0c70d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Words...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "276b29ffb6b544c0b57e380ce0af7c64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c7d759b191442e5b291afbba9c454ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df3 = data_cleaning(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_article</th>\n",
       "      <th>num_punctuations</th>\n",
       "      <th>no_of_stopwords</th>\n",
       "      <th>no_of_quesMarks</th>\n",
       "      <th>no_of_exclamation</th>\n",
       "      <th>no_of_sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cc_cd</th>\n",
       "      <th>determiner</th>\n",
       "      <th>foreign_w</th>\n",
       "      <th>conj_prep</th>\n",
       "      <th>adjective</th>\n",
       "      <th>modal</th>\n",
       "      <th>noun</th>\n",
       "      <th>adverb</th>\n",
       "      <th>verb</th>\n",
       "      <th>article_len</th>\n",
       "      <th>negations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>news release unemployment rise wisconsin paul ...</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>black turnout soft early voting boding hillary...</td>\n",
       "      <td>47</td>\n",
       "      <td>261</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>Positive</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>103</td>\n",
       "      <td>15</td>\n",
       "      <td>48</td>\n",
       "      <td>1869</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>television interview milwaukee county safe year</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>thing learned general contractor foundation li...</td>\n",
       "      <td>258</td>\n",
       "      <td>1242</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>Positive</td>\n",
       "      <td>131</td>\n",
       "      <td>209</td>\n",
       "      <td>1</td>\n",
       "      <td>196</td>\n",
       "      <td>196</td>\n",
       "      <td>42</td>\n",
       "      <td>476</td>\n",
       "      <td>97</td>\n",
       "      <td>423</td>\n",
       "      <td>10541</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>statement responding rick scott state state sp...</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30933</th>\n",
       "      <td>1</td>\n",
       "      <td>richardson passed nation giving national guard...</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30934</th>\n",
       "      <td>0</td>\n",
       "      <td>khodorkovsky putin going cozy washington print...</td>\n",
       "      <td>121</td>\n",
       "      <td>553</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>Positive</td>\n",
       "      <td>19</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>69</td>\n",
       "      <td>19</td>\n",
       "      <td>184</td>\n",
       "      <td>46</td>\n",
       "      <td>161</td>\n",
       "      <td>4216</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30935</th>\n",
       "      <td>0</td>\n",
       "      <td>coup stolen election rumor coup watching mediu...</td>\n",
       "      <td>74</td>\n",
       "      <td>378</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>37</td>\n",
       "      <td>Negative</td>\n",
       "      <td>18</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>69</td>\n",
       "      <td>7</td>\n",
       "      <td>164</td>\n",
       "      <td>25</td>\n",
       "      <td>130</td>\n",
       "      <td>3203</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30936</th>\n",
       "      <td>1</td>\n",
       "      <td>doomed carrying brazilian team reportedly fuel...</td>\n",
       "      <td>87</td>\n",
       "      <td>504</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>Negative</td>\n",
       "      <td>24</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>51</td>\n",
       "      <td>5</td>\n",
       "      <td>202</td>\n",
       "      <td>24</td>\n",
       "      <td>121</td>\n",
       "      <td>3809</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30937</th>\n",
       "      <td>1</td>\n",
       "      <td>burger king google doesnt google york time goo...</td>\n",
       "      <td>90</td>\n",
       "      <td>511</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>Positive</td>\n",
       "      <td>23</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "      <td>232</td>\n",
       "      <td>26</td>\n",
       "      <td>136</td>\n",
       "      <td>4072</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30938 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                    cleaned_article  \\\n",
       "0          0  news release unemployment rise wisconsin paul ...   \n",
       "1          0  black turnout soft early voting boding hillary...   \n",
       "2          0    television interview milwaukee county safe year   \n",
       "3          0  thing learned general contractor foundation li...   \n",
       "4          1  statement responding rick scott state state sp...   \n",
       "...      ...                                                ...   \n",
       "30933      1  richardson passed nation giving national guard...   \n",
       "30934      0  khodorkovsky putin going cozy washington print...   \n",
       "30935      0  coup stolen election rumor coup watching mediu...   \n",
       "30936      1  doomed carrying brazilian team reportedly fuel...   \n",
       "30937      1  burger king google doesnt google york time goo...   \n",
       "\n",
       "       num_punctuations  no_of_stopwords  no_of_quesMarks  no_of_exclamation  \\\n",
       "0                     1               18                0                  0   \n",
       "1                    47              261                0                  0   \n",
       "2                     1               14                0                  0   \n",
       "3                   258             1242                2                  0   \n",
       "4                     4               11                0                  0   \n",
       "...                 ...              ...              ...                ...   \n",
       "30933                 4               22                0                  0   \n",
       "30934               121              553               11                  0   \n",
       "30935                74              378                7                  6   \n",
       "30936                87              504                0                  2   \n",
       "30937                90              511                1                  1   \n",
       "\n",
       "       no_of_sentence sentiment  cc_cd  determiner  foreign_w  conj_prep  \\\n",
       "0                   1  Negative      0           2          0          4   \n",
       "1                  11  Positive     17          25          0         41   \n",
       "2                   1  Negative      2           3          0          1   \n",
       "3                  80  Positive    131         209          1        196   \n",
       "4                   3   Neutral      1           2          0          1   \n",
       "...               ...       ...    ...         ...        ...        ...   \n",
       "30933               2  Positive      0           3          0          2   \n",
       "30934              38  Positive     19          62          0         81   \n",
       "30935              37  Negative     18          56          0         62   \n",
       "30936              32  Negative     24          83          0         91   \n",
       "30937              29  Positive     23          72          0         82   \n",
       "\n",
       "       adjective  modal  noun  adverb  verb  article_len  negations  \n",
       "0              0      0    10       1     3          131          0  \n",
       "1             43      2   103      15    48         1869          1  \n",
       "2              1      0     6       3     2           94          1  \n",
       "3            196     42   476      97   423        10541         19  \n",
       "4              1      1     8       1     7          126          0  \n",
       "...          ...    ...   ...     ...   ...          ...        ...  \n",
       "30933          2      0    10       0     3          108          0  \n",
       "30934         69     19   184      46   161         4216         19  \n",
       "30935         69      7   164      25   130         3203          5  \n",
       "30936         51      5   202      24   121         3809          4  \n",
       "30937         59      4   232      26   136         4072          4  \n",
       "\n",
       "[30938 rows x 19 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df3['cleaned_article'] = df3['cleaned_article'].apply(lambda x : \" \".join(x))\n",
    "#df3.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8936de8f9a7b40f7a1deebde307f9255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Count\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27d2d2144d794b7ba528e8ab509ae979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Word Count\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "143648c3c5ce47158fcd7bcb63c07b05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique Words\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b1dea751fd64a27808c49effe4dbbe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Chars\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2711784ee4c049baab5dd5f48850d923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_article</th>\n",
       "      <th>num_punctuations</th>\n",
       "      <th>no_of_stopwords</th>\n",
       "      <th>no_of_quesMarks</th>\n",
       "      <th>no_of_exclamation</th>\n",
       "      <th>no_of_sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cc_cd</th>\n",
       "      <th>determiner</th>\n",
       "      <th>...</th>\n",
       "      <th>noun</th>\n",
       "      <th>adverb</th>\n",
       "      <th>verb</th>\n",
       "      <th>article_len</th>\n",
       "      <th>negations</th>\n",
       "      <th>polarity</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>num_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>news release unemployment rise wisconsin paul ...</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>7.090909</td>\n",
       "      <td>11</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>black turnout soft early voting boding hillary...</td>\n",
       "      <td>47</td>\n",
       "      <td>261</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>Positive</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>15</td>\n",
       "      <td>48</td>\n",
       "      <td>1869</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.023781</td>\n",
       "      <td>163</td>\n",
       "      <td>6.705521</td>\n",
       "      <td>116</td>\n",
       "      <td>1255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>television interview milwaukee county safe year</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>6</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>thing learned general contractor foundation li...</td>\n",
       "      <td>258</td>\n",
       "      <td>1242</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>Positive</td>\n",
       "      <td>131</td>\n",
       "      <td>209</td>\n",
       "      <td>...</td>\n",
       "      <td>476</td>\n",
       "      <td>97</td>\n",
       "      <td>423</td>\n",
       "      <td>10541</td>\n",
       "      <td>19</td>\n",
       "      <td>0.176372</td>\n",
       "      <td>678</td>\n",
       "      <td>6.328909</td>\n",
       "      <td>391</td>\n",
       "      <td>4968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>statement responding rick scott state state sp...</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>9</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30933</th>\n",
       "      <td>1</td>\n",
       "      <td>richardson passed nation giving national guard...</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>6.777778</td>\n",
       "      <td>9</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30934</th>\n",
       "      <td>0</td>\n",
       "      <td>khodorkovsky putin going cozy washington print...</td>\n",
       "      <td>121</td>\n",
       "      <td>553</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>Positive</td>\n",
       "      <td>19</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>184</td>\n",
       "      <td>46</td>\n",
       "      <td>161</td>\n",
       "      <td>4216</td>\n",
       "      <td>19</td>\n",
       "      <td>0.033517</td>\n",
       "      <td>302</td>\n",
       "      <td>6.801325</td>\n",
       "      <td>172</td>\n",
       "      <td>2355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30935</th>\n",
       "      <td>0</td>\n",
       "      <td>coup stolen election rumor coup watching mediu...</td>\n",
       "      <td>74</td>\n",
       "      <td>378</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>37</td>\n",
       "      <td>Negative</td>\n",
       "      <td>18</td>\n",
       "      <td>56</td>\n",
       "      <td>...</td>\n",
       "      <td>164</td>\n",
       "      <td>25</td>\n",
       "      <td>130</td>\n",
       "      <td>3203</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.012531</td>\n",
       "      <td>250</td>\n",
       "      <td>6.420000</td>\n",
       "      <td>174</td>\n",
       "      <td>1854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30936</th>\n",
       "      <td>1</td>\n",
       "      <td>doomed carrying brazilian team reportedly fuel...</td>\n",
       "      <td>87</td>\n",
       "      <td>504</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>Negative</td>\n",
       "      <td>24</td>\n",
       "      <td>83</td>\n",
       "      <td>...</td>\n",
       "      <td>202</td>\n",
       "      <td>24</td>\n",
       "      <td>121</td>\n",
       "      <td>3809</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.020977</td>\n",
       "      <td>300</td>\n",
       "      <td>6.740000</td>\n",
       "      <td>213</td>\n",
       "      <td>2321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30937</th>\n",
       "      <td>1</td>\n",
       "      <td>burger king google doesnt google york time goo...</td>\n",
       "      <td>90</td>\n",
       "      <td>511</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>Positive</td>\n",
       "      <td>23</td>\n",
       "      <td>72</td>\n",
       "      <td>...</td>\n",
       "      <td>232</td>\n",
       "      <td>26</td>\n",
       "      <td>136</td>\n",
       "      <td>4072</td>\n",
       "      <td>4</td>\n",
       "      <td>0.094553</td>\n",
       "      <td>327</td>\n",
       "      <td>6.672783</td>\n",
       "      <td>220</td>\n",
       "      <td>2508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30938 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                    cleaned_article  \\\n",
       "0          0  news release unemployment rise wisconsin paul ...   \n",
       "1          0  black turnout soft early voting boding hillary...   \n",
       "2          0    television interview milwaukee county safe year   \n",
       "3          0  thing learned general contractor foundation li...   \n",
       "4          1  statement responding rick scott state state sp...   \n",
       "...      ...                                                ...   \n",
       "30933      1  richardson passed nation giving national guard...   \n",
       "30934      0  khodorkovsky putin going cozy washington print...   \n",
       "30935      0  coup stolen election rumor coup watching mediu...   \n",
       "30936      1  doomed carrying brazilian team reportedly fuel...   \n",
       "30937      1  burger king google doesnt google york time goo...   \n",
       "\n",
       "       num_punctuations  no_of_stopwords  no_of_quesMarks  no_of_exclamation  \\\n",
       "0                     1               18                0                  0   \n",
       "1                    47              261                0                  0   \n",
       "2                     1               14                0                  0   \n",
       "3                   258             1242                2                  0   \n",
       "4                     4               11                0                  0   \n",
       "...                 ...              ...              ...                ...   \n",
       "30933                 4               22                0                  0   \n",
       "30934               121              553               11                  0   \n",
       "30935                74              378                7                  6   \n",
       "30936                87              504                0                  2   \n",
       "30937                90              511                1                  1   \n",
       "\n",
       "       no_of_sentence sentiment  cc_cd  determiner  ...  noun  adverb  verb  \\\n",
       "0                   1  Negative      0           2  ...    10       1     3   \n",
       "1                  11  Positive     17          25  ...   103      15    48   \n",
       "2                   1  Negative      2           3  ...     6       3     2   \n",
       "3                  80  Positive    131         209  ...   476      97   423   \n",
       "4                   3   Neutral      1           2  ...     8       1     7   \n",
       "...               ...       ...    ...         ...  ...   ...     ...   ...   \n",
       "30933               2  Positive      0           3  ...    10       0     3   \n",
       "30934              38  Positive     19          62  ...   184      46   161   \n",
       "30935              37  Negative     18          56  ...   164      25   130   \n",
       "30936              32  Negative     24          83  ...   202      24   121   \n",
       "30937              29  Positive     23          72  ...   232      26   136   \n",
       "\n",
       "       article_len  negations  polarity  word_count  avg_word_len  \\\n",
       "0              131          0  0.000000          11      7.090909   \n",
       "1             1869          1 -0.023781         163      6.705521   \n",
       "2               94          1  0.500000           6      7.000000   \n",
       "3            10541         19  0.176372         678      6.328909   \n",
       "4              126          0  0.000000          12      6.166667   \n",
       "...            ...        ...       ...         ...           ...   \n",
       "30933          108          0  0.000000           9      6.777778   \n",
       "30934         4216         19  0.033517         302      6.801325   \n",
       "30935         3203          5 -0.012531         250      6.420000   \n",
       "30936         3809          4 -0.020977         300      6.740000   \n",
       "30937         4072          4  0.094553         327      6.672783   \n",
       "\n",
       "       num_unique_words  num_chars  \n",
       "0                    11         88  \n",
       "1                   116       1255  \n",
       "2                     6         47  \n",
       "3                   391       4968  \n",
       "4                     9         85  \n",
       "...                 ...        ...  \n",
       "30933                 9         69  \n",
       "30934               172       2355  \n",
       "30935               174       1854  \n",
       "30936               213       2321  \n",
       "30937               220       2508  \n",
       "\n",
       "[30938 rows x 24 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_engineering(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.drop(df3[df3['article_len'] == 0].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop_noword_article(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_article</th>\n",
       "      <th>num_punctuations</th>\n",
       "      <th>no_of_stopwords</th>\n",
       "      <th>no_of_quesMarks</th>\n",
       "      <th>no_of_exclamation</th>\n",
       "      <th>no_of_sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cc_cd</th>\n",
       "      <th>determiner</th>\n",
       "      <th>...</th>\n",
       "      <th>noun</th>\n",
       "      <th>adverb</th>\n",
       "      <th>verb</th>\n",
       "      <th>article_len</th>\n",
       "      <th>negations</th>\n",
       "      <th>polarity</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>num_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [label, cleaned_article, num_punctuations, no_of_stopwords, no_of_quesMarks, no_of_exclamation, no_of_sentence, sentiment, cc_cd, determiner, foreign_w, conj_prep, adjective, modal, noun, adverb, verb, article_len, negations, polarity, word_count, avg_word_len, num_unique_words, num_chars]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 24 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3[df3['article_len'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv(\"Cleaned/cleaned_data_3.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label', 'cleaned_article', 'num_punctuations', 'no_of_stopwords',\n",
       "       'no_of_quesMarks', 'no_of_exclamation', 'no_of_sentence', 'sentiment',\n",
       "       'cc_cd', 'determiner', 'foreign_w', 'conj_prep', 'adjective', 'modal',\n",
       "       'noun', 'adverb', 'verb', 'article_len', 'negations', 'polarity',\n",
       "       'word_count', 'avg_word_len', 'num_unique_words', 'num_chars'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 4    (Test 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20800</td>\n",
       "      <td>Specter of Trump Loosens Tongues, if Not Purse...</td>\n",
       "      <td>David Streitfeld</td>\n",
       "      <td>PALO ALTO, Calif.  —   After years of scorning...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20801</td>\n",
       "      <td>Russian warships ready to strike terrorists ne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Russian warships ready to strike terrorists ne...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title            author  \\\n",
       "0  20800  Specter of Trump Loosens Tongues, if Not Purse...  David Streitfeld   \n",
       "1  20801  Russian warships ready to strike terrorists ne...               NaN   \n",
       "\n",
       "                                                text  label  \n",
       "0  PALO ALTO, Calif.  —   After years of scorning...      0  \n",
       "1  Russian warships ready to strike terrorists ne...      1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = pd.read_csv(\"Test/data1.csv\")\n",
    "df4.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "title     122\n",
       "author    503\n",
       "text        7\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As per source label 1 represent fake whereas label 0 represents Real news\n",
    "# Converting 0 to 1 and 1 to 0 as per our problem definition \n",
    "df4.label.replace({0:1, 1:0}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2861\n",
       "1    2339\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.fillna(' ', inplace = True)\n",
    "df4['cleaned_article'] = df4['title'] + \" \" + df4['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.drop(['id', 'title', 'author', 'text'], axis = 1 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label              0\n",
       "cleaned_article    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f555a924a345474e8ab2208604fcf122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32d50f951e764945b1992627ca4c75e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0edf04b76b5492286a5314b3aabe584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Featurization\n",
      "Number of punctuations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d98f3826e0b403d9c75ca4ee8919675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Stopwords\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5df0f28adc54fe6bef622aa2b05ec6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of question marks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ddaa26e3409487093ab5654bcc7a1bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Exclamation Marks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c30933061574fa1a191e7a11407c17a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Sentences\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3f6476cf5694f459b7798101e0bd435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc90f9ee0ac84d038079a2689b163e70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS TAGGING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5200/5200 [02:15<00:00, 38.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning......\n",
      "Special Char\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4f4d7d3a6d24347b831b4187ef03430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article Length\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adf4c126c076432bbc853369702f6f0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmetization\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3029d3601e96497892baf7da1e8c54ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Words...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1975c03e750c4fe3beeeef555700f559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c53482a0dc724279961dc677130a0f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_article</th>\n",
       "      <th>num_punctuations</th>\n",
       "      <th>no_of_stopwords</th>\n",
       "      <th>no_of_quesMarks</th>\n",
       "      <th>no_of_exclamation</th>\n",
       "      <th>no_of_sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cc_cd</th>\n",
       "      <th>determiner</th>\n",
       "      <th>foreign_w</th>\n",
       "      <th>conj_prep</th>\n",
       "      <th>adjective</th>\n",
       "      <th>modal</th>\n",
       "      <th>noun</th>\n",
       "      <th>adverb</th>\n",
       "      <th>verb</th>\n",
       "      <th>article_len</th>\n",
       "      <th>negations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>specter trump loosens tongue purse string sili...</td>\n",
       "      <td>212</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>Positive</td>\n",
       "      <td>56</td>\n",
       "      <td>115</td>\n",
       "      <td>2</td>\n",
       "      <td>139</td>\n",
       "      <td>146</td>\n",
       "      <td>11</td>\n",
       "      <td>396</td>\n",
       "      <td>61</td>\n",
       "      <td>265</td>\n",
       "      <td>7680</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>russian warship ready strike terrorist near al...</td>\n",
       "      <td>43</td>\n",
       "      <td>234</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>Negative</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>83</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>1564</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>nodapl native american leader stay winter file...</td>\n",
       "      <td>96</td>\n",
       "      <td>573</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>Negative</td>\n",
       "      <td>38</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>8</td>\n",
       "      <td>235</td>\n",
       "      <td>22</td>\n",
       "      <td>138</td>\n",
       "      <td>4390</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tebow attempt comeback time baseball york time...</td>\n",
       "      <td>98</td>\n",
       "      <td>438</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>Positive</td>\n",
       "      <td>42</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>66</td>\n",
       "      <td>11</td>\n",
       "      <td>215</td>\n",
       "      <td>15</td>\n",
       "      <td>104</td>\n",
       "      <td>3448</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>keiser report meme view comment like time hist...</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Positive</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>524</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                    cleaned_article  num_punctuations  \\\n",
       "0      1  specter trump loosens tongue purse string sili...               212   \n",
       "1      0  russian warship ready strike terrorist near al...                43   \n",
       "2      1  nodapl native american leader stay winter file...                96   \n",
       "3      0  tebow attempt comeback time baseball york time...                98   \n",
       "4      0  keiser report meme view comment like time hist...                16   \n",
       "\n",
       "   no_of_stopwords  no_of_quesMarks  no_of_exclamation  no_of_sentence  \\\n",
       "0              999                0                  0              75   \n",
       "1              234                0                  0              10   \n",
       "2              573                0                  4              32   \n",
       "3              438                1                  0              28   \n",
       "4               64                0                  0               5   \n",
       "\n",
       "  sentiment  cc_cd  determiner  foreign_w  conj_prep  adjective  modal  noun  \\\n",
       "0  Positive     56         115          2        139        146     11   396   \n",
       "1  Negative      7          27          0         30         34      4    83   \n",
       "2  Negative     38          50          0         83         83      8   235   \n",
       "3  Positive     42          63          0         82         66     11   215   \n",
       "4  Positive      7           6          0         10         10      1    34   \n",
       "\n",
       "   adverb  verb  article_len  negations  \n",
       "0      61   265         7680         15  \n",
       "1       3    38         1564          1  \n",
       "2      22   138         4390          1  \n",
       "3      15   104         3448          4  \n",
       "4       5    15          524          1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = data_cleaning(df4)\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df4['cleaned_article'] = df4['cleaned_article'].apply(lambda x : \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb732458fb97496cbf59ef1a4a32fc29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Count\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4d1b1da2bda42cb878eab2480fe6e6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Word Count\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06243e5625cc43c5841acf7a64708f04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique Words\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ac37fd9026430b95efdc66429f24af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Chars\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a65b3ba68aa94ec1b973ce82aed7e5f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_article</th>\n",
       "      <th>num_punctuations</th>\n",
       "      <th>no_of_stopwords</th>\n",
       "      <th>no_of_quesMarks</th>\n",
       "      <th>no_of_exclamation</th>\n",
       "      <th>no_of_sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cc_cd</th>\n",
       "      <th>determiner</th>\n",
       "      <th>...</th>\n",
       "      <th>noun</th>\n",
       "      <th>adverb</th>\n",
       "      <th>verb</th>\n",
       "      <th>article_len</th>\n",
       "      <th>negations</th>\n",
       "      <th>polarity</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>num_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>specter trump loosens tongue purse string sili...</td>\n",
       "      <td>212</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>Positive</td>\n",
       "      <td>56</td>\n",
       "      <td>115</td>\n",
       "      <td>...</td>\n",
       "      <td>396</td>\n",
       "      <td>61</td>\n",
       "      <td>265</td>\n",
       "      <td>7680</td>\n",
       "      <td>15</td>\n",
       "      <td>0.053472</td>\n",
       "      <td>623</td>\n",
       "      <td>6.778491</td>\n",
       "      <td>409</td>\n",
       "      <td>4845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>russian warship ready strike terrorist near al...</td>\n",
       "      <td>43</td>\n",
       "      <td>234</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>Negative</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>83</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>1564</td>\n",
       "      <td>1</td>\n",
       "      <td>0.074048</td>\n",
       "      <td>132</td>\n",
       "      <td>7.015152</td>\n",
       "      <td>79</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>nodapl native american leader stay winter file...</td>\n",
       "      <td>96</td>\n",
       "      <td>573</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>Negative</td>\n",
       "      <td>38</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>235</td>\n",
       "      <td>22</td>\n",
       "      <td>138</td>\n",
       "      <td>4390</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.003599</td>\n",
       "      <td>373</td>\n",
       "      <td>6.863271</td>\n",
       "      <td>225</td>\n",
       "      <td>2932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tebow attempt comeback time baseball york time...</td>\n",
       "      <td>98</td>\n",
       "      <td>438</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>Positive</td>\n",
       "      <td>42</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>215</td>\n",
       "      <td>15</td>\n",
       "      <td>104</td>\n",
       "      <td>3448</td>\n",
       "      <td>4</td>\n",
       "      <td>0.168915</td>\n",
       "      <td>274</td>\n",
       "      <td>6.186131</td>\n",
       "      <td>191</td>\n",
       "      <td>1968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>keiser report meme view comment like time hist...</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Positive</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>524</td>\n",
       "      <td>1</td>\n",
       "      <td>0.084167</td>\n",
       "      <td>44</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>39</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5195</th>\n",
       "      <td>1</td>\n",
       "      <td>bangladeshi traffic york time dysfunction plag...</td>\n",
       "      <td>445</td>\n",
       "      <td>2440</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>174</td>\n",
       "      <td>Negative</td>\n",
       "      <td>159</td>\n",
       "      <td>352</td>\n",
       "      <td>...</td>\n",
       "      <td>939</td>\n",
       "      <td>139</td>\n",
       "      <td>527</td>\n",
       "      <td>17712</td>\n",
       "      <td>23</td>\n",
       "      <td>0.009160</td>\n",
       "      <td>1439</td>\n",
       "      <td>6.596247</td>\n",
       "      <td>920</td>\n",
       "      <td>10930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5196</th>\n",
       "      <td>0</td>\n",
       "      <td>john kasich sign abortion ohio veto restrictiv...</td>\n",
       "      <td>72</td>\n",
       "      <td>462</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>Negative</td>\n",
       "      <td>31</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>196</td>\n",
       "      <td>22</td>\n",
       "      <td>96</td>\n",
       "      <td>3353</td>\n",
       "      <td>5</td>\n",
       "      <td>0.129097</td>\n",
       "      <td>266</td>\n",
       "      <td>6.586466</td>\n",
       "      <td>174</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5197</th>\n",
       "      <td>1</td>\n",
       "      <td>california today exactly sushi york time good ...</td>\n",
       "      <td>159</td>\n",
       "      <td>746</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>Negative</td>\n",
       "      <td>43</td>\n",
       "      <td>89</td>\n",
       "      <td>...</td>\n",
       "      <td>323</td>\n",
       "      <td>34</td>\n",
       "      <td>170</td>\n",
       "      <td>5498</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.012897</td>\n",
       "      <td>469</td>\n",
       "      <td>6.526652</td>\n",
       "      <td>376</td>\n",
       "      <td>3529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5198</th>\n",
       "      <td>0</td>\n",
       "      <td>marine deployed russian border norway previous...</td>\n",
       "      <td>31</td>\n",
       "      <td>325</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>Negative</td>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "      <td>...</td>\n",
       "      <td>105</td>\n",
       "      <td>29</td>\n",
       "      <td>97</td>\n",
       "      <td>2640</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.049270</td>\n",
       "      <td>192</td>\n",
       "      <td>6.520833</td>\n",
       "      <td>131</td>\n",
       "      <td>1443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5199</th>\n",
       "      <td>1</td>\n",
       "      <td>awkward onscreen york time youve seen series p...</td>\n",
       "      <td>220</td>\n",
       "      <td>1064</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>Positive</td>\n",
       "      <td>58</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>404</td>\n",
       "      <td>93</td>\n",
       "      <td>261</td>\n",
       "      <td>8091</td>\n",
       "      <td>13</td>\n",
       "      <td>0.080816</td>\n",
       "      <td>576</td>\n",
       "      <td>6.706597</td>\n",
       "      <td>442</td>\n",
       "      <td>4438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5200 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                    cleaned_article  \\\n",
       "0         1  specter trump loosens tongue purse string sili...   \n",
       "1         0  russian warship ready strike terrorist near al...   \n",
       "2         1  nodapl native american leader stay winter file...   \n",
       "3         0  tebow attempt comeback time baseball york time...   \n",
       "4         0  keiser report meme view comment like time hist...   \n",
       "...     ...                                                ...   \n",
       "5195      1  bangladeshi traffic york time dysfunction plag...   \n",
       "5196      0  john kasich sign abortion ohio veto restrictiv...   \n",
       "5197      1  california today exactly sushi york time good ...   \n",
       "5198      0  marine deployed russian border norway previous...   \n",
       "5199      1  awkward onscreen york time youve seen series p...   \n",
       "\n",
       "      num_punctuations  no_of_stopwords  no_of_quesMarks  no_of_exclamation  \\\n",
       "0                  212              999                0                  0   \n",
       "1                   43              234                0                  0   \n",
       "2                   96              573                0                  4   \n",
       "3                   98              438                1                  0   \n",
       "4                   16               64                0                  0   \n",
       "...                ...              ...              ...                ...   \n",
       "5195               445             2440                1                  4   \n",
       "5196                72              462                0                  0   \n",
       "5197               159              746                4                  0   \n",
       "5198                31              325                2                  0   \n",
       "5199               220             1064                7                  1   \n",
       "\n",
       "      no_of_sentence sentiment  cc_cd  determiner  ...  noun  adverb  verb  \\\n",
       "0                 75  Positive     56         115  ...   396      61   265   \n",
       "1                 10  Negative      7          27  ...    83       3    38   \n",
       "2                 32  Negative     38          50  ...   235      22   138   \n",
       "3                 28  Positive     42          63  ...   215      15   104   \n",
       "4                  5  Positive      7           6  ...    34       5    15   \n",
       "...              ...       ...    ...         ...  ...   ...     ...   ...   \n",
       "5195             174  Negative    159         352  ...   939     139   527   \n",
       "5196              27  Negative     31          70  ...   196      22    96   \n",
       "5197              65  Negative     43          89  ...   323      34   170   \n",
       "5198              18  Negative      8          56  ...   105      29    97   \n",
       "5199              71  Positive     58         150  ...   404      93   261   \n",
       "\n",
       "      article_len  negations  polarity  word_count  avg_word_len  \\\n",
       "0            7680         15  0.053472         623      6.778491   \n",
       "1            1564          1  0.074048         132      7.015152   \n",
       "2            4390          1 -0.003599         373      6.863271   \n",
       "3            3448          4  0.168915         274      6.186131   \n",
       "4             524          1  0.084167          44      6.250000   \n",
       "...           ...        ...       ...         ...           ...   \n",
       "5195        17712         23  0.009160        1439      6.596247   \n",
       "5196         3353          5  0.129097         266      6.586466   \n",
       "5197         5498          1 -0.012897         469      6.526652   \n",
       "5198         2640          6 -0.049270         192      6.520833   \n",
       "5199         8091         13  0.080816         576      6.706597   \n",
       "\n",
       "      num_unique_words  num_chars  \n",
       "0                  409       4845  \n",
       "1                   79       1057  \n",
       "2                  225       2932  \n",
       "3                  191       1968  \n",
       "4                   39        318  \n",
       "...                ...        ...  \n",
       "5195               920      10930  \n",
       "5196               174       2017  \n",
       "5197               376       3529  \n",
       "5198               131       1443  \n",
       "5199               442       4438  \n",
       "\n",
       "[5200 rows x 24 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_engineering(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_article</th>\n",
       "      <th>num_punctuations</th>\n",
       "      <th>no_of_stopwords</th>\n",
       "      <th>no_of_quesMarks</th>\n",
       "      <th>no_of_exclamation</th>\n",
       "      <th>no_of_sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cc_cd</th>\n",
       "      <th>determiner</th>\n",
       "      <th>...</th>\n",
       "      <th>noun</th>\n",
       "      <th>adverb</th>\n",
       "      <th>verb</th>\n",
       "      <th>article_len</th>\n",
       "      <th>negations</th>\n",
       "      <th>polarity</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>num_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>specter trump loosens tongue purse string sili...</td>\n",
       "      <td>212</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>Positive</td>\n",
       "      <td>56</td>\n",
       "      <td>115</td>\n",
       "      <td>...</td>\n",
       "      <td>396</td>\n",
       "      <td>61</td>\n",
       "      <td>265</td>\n",
       "      <td>7680</td>\n",
       "      <td>15</td>\n",
       "      <td>0.053472</td>\n",
       "      <td>623</td>\n",
       "      <td>6.778491</td>\n",
       "      <td>409</td>\n",
       "      <td>4845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>russian warship ready strike terrorist near al...</td>\n",
       "      <td>43</td>\n",
       "      <td>234</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>Negative</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>83</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>1564</td>\n",
       "      <td>1</td>\n",
       "      <td>0.074048</td>\n",
       "      <td>132</td>\n",
       "      <td>7.015152</td>\n",
       "      <td>79</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>nodapl native american leader stay winter file...</td>\n",
       "      <td>96</td>\n",
       "      <td>573</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>Negative</td>\n",
       "      <td>38</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>235</td>\n",
       "      <td>22</td>\n",
       "      <td>138</td>\n",
       "      <td>4390</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.003599</td>\n",
       "      <td>373</td>\n",
       "      <td>6.863271</td>\n",
       "      <td>225</td>\n",
       "      <td>2932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tebow attempt comeback time baseball york time...</td>\n",
       "      <td>98</td>\n",
       "      <td>438</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>Positive</td>\n",
       "      <td>42</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>215</td>\n",
       "      <td>15</td>\n",
       "      <td>104</td>\n",
       "      <td>3448</td>\n",
       "      <td>4</td>\n",
       "      <td>0.168915</td>\n",
       "      <td>274</td>\n",
       "      <td>6.186131</td>\n",
       "      <td>191</td>\n",
       "      <td>1968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>keiser report meme view comment like time hist...</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Positive</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>524</td>\n",
       "      <td>1</td>\n",
       "      <td>0.084167</td>\n",
       "      <td>44</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>39</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5195</th>\n",
       "      <td>1</td>\n",
       "      <td>bangladeshi traffic york time dysfunction plag...</td>\n",
       "      <td>445</td>\n",
       "      <td>2440</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>174</td>\n",
       "      <td>Negative</td>\n",
       "      <td>159</td>\n",
       "      <td>352</td>\n",
       "      <td>...</td>\n",
       "      <td>939</td>\n",
       "      <td>139</td>\n",
       "      <td>527</td>\n",
       "      <td>17712</td>\n",
       "      <td>23</td>\n",
       "      <td>0.009160</td>\n",
       "      <td>1439</td>\n",
       "      <td>6.596247</td>\n",
       "      <td>920</td>\n",
       "      <td>10930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5196</th>\n",
       "      <td>0</td>\n",
       "      <td>john kasich sign abortion ohio veto restrictiv...</td>\n",
       "      <td>72</td>\n",
       "      <td>462</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>Negative</td>\n",
       "      <td>31</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>196</td>\n",
       "      <td>22</td>\n",
       "      <td>96</td>\n",
       "      <td>3353</td>\n",
       "      <td>5</td>\n",
       "      <td>0.129097</td>\n",
       "      <td>266</td>\n",
       "      <td>6.586466</td>\n",
       "      <td>174</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5197</th>\n",
       "      <td>1</td>\n",
       "      <td>california today exactly sushi york time good ...</td>\n",
       "      <td>159</td>\n",
       "      <td>746</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>Negative</td>\n",
       "      <td>43</td>\n",
       "      <td>89</td>\n",
       "      <td>...</td>\n",
       "      <td>323</td>\n",
       "      <td>34</td>\n",
       "      <td>170</td>\n",
       "      <td>5498</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.012897</td>\n",
       "      <td>469</td>\n",
       "      <td>6.526652</td>\n",
       "      <td>376</td>\n",
       "      <td>3529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5198</th>\n",
       "      <td>0</td>\n",
       "      <td>marine deployed russian border norway previous...</td>\n",
       "      <td>31</td>\n",
       "      <td>325</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>Negative</td>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "      <td>...</td>\n",
       "      <td>105</td>\n",
       "      <td>29</td>\n",
       "      <td>97</td>\n",
       "      <td>2640</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.049270</td>\n",
       "      <td>192</td>\n",
       "      <td>6.520833</td>\n",
       "      <td>131</td>\n",
       "      <td>1443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5199</th>\n",
       "      <td>1</td>\n",
       "      <td>awkward onscreen york time youve seen series p...</td>\n",
       "      <td>220</td>\n",
       "      <td>1064</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>Positive</td>\n",
       "      <td>58</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>404</td>\n",
       "      <td>93</td>\n",
       "      <td>261</td>\n",
       "      <td>8091</td>\n",
       "      <td>13</td>\n",
       "      <td>0.080816</td>\n",
       "      <td>576</td>\n",
       "      <td>6.706597</td>\n",
       "      <td>442</td>\n",
       "      <td>4438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5185 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                    cleaned_article  \\\n",
       "0         1  specter trump loosens tongue purse string sili...   \n",
       "1         0  russian warship ready strike terrorist near al...   \n",
       "2         1  nodapl native american leader stay winter file...   \n",
       "3         0  tebow attempt comeback time baseball york time...   \n",
       "4         0  keiser report meme view comment like time hist...   \n",
       "...     ...                                                ...   \n",
       "5195      1  bangladeshi traffic york time dysfunction plag...   \n",
       "5196      0  john kasich sign abortion ohio veto restrictiv...   \n",
       "5197      1  california today exactly sushi york time good ...   \n",
       "5198      0  marine deployed russian border norway previous...   \n",
       "5199      1  awkward onscreen york time youve seen series p...   \n",
       "\n",
       "      num_punctuations  no_of_stopwords  no_of_quesMarks  no_of_exclamation  \\\n",
       "0                  212              999                0                  0   \n",
       "1                   43              234                0                  0   \n",
       "2                   96              573                0                  4   \n",
       "3                   98              438                1                  0   \n",
       "4                   16               64                0                  0   \n",
       "...                ...              ...              ...                ...   \n",
       "5195               445             2440                1                  4   \n",
       "5196                72              462                0                  0   \n",
       "5197               159              746                4                  0   \n",
       "5198                31              325                2                  0   \n",
       "5199               220             1064                7                  1   \n",
       "\n",
       "      no_of_sentence sentiment  cc_cd  determiner  ...  noun  adverb  verb  \\\n",
       "0                 75  Positive     56         115  ...   396      61   265   \n",
       "1                 10  Negative      7          27  ...    83       3    38   \n",
       "2                 32  Negative     38          50  ...   235      22   138   \n",
       "3                 28  Positive     42          63  ...   215      15   104   \n",
       "4                  5  Positive      7           6  ...    34       5    15   \n",
       "...              ...       ...    ...         ...  ...   ...     ...   ...   \n",
       "5195             174  Negative    159         352  ...   939     139   527   \n",
       "5196              27  Negative     31          70  ...   196      22    96   \n",
       "5197              65  Negative     43          89  ...   323      34   170   \n",
       "5198              18  Negative      8          56  ...   105      29    97   \n",
       "5199              71  Positive     58         150  ...   404      93   261   \n",
       "\n",
       "      article_len  negations  polarity  word_count  avg_word_len  \\\n",
       "0            7680         15  0.053472         623      6.778491   \n",
       "1            1564          1  0.074048         132      7.015152   \n",
       "2            4390          1 -0.003599         373      6.863271   \n",
       "3            3448          4  0.168915         274      6.186131   \n",
       "4             524          1  0.084167          44      6.250000   \n",
       "...           ...        ...       ...         ...           ...   \n",
       "5195        17712         23  0.009160        1439      6.596247   \n",
       "5196         3353          5  0.129097         266      6.586466   \n",
       "5197         5498          1 -0.012897         469      6.526652   \n",
       "5198         2640          6 -0.049270         192      6.520833   \n",
       "5199         8091         13  0.080816         576      6.706597   \n",
       "\n",
       "      num_unique_words  num_chars  \n",
       "0                  409       4845  \n",
       "1                   79       1057  \n",
       "2                  225       2932  \n",
       "3                  191       1968  \n",
       "4                   39        318  \n",
       "...                ...        ...  \n",
       "5195               920      10930  \n",
       "5196               174       2017  \n",
       "5197               376       3529  \n",
       "5198               131       1443  \n",
       "5199               442       4438  \n",
       "\n",
       "[5185 rows x 24 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_noword_article(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.to_csv(\"Test/test1.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 5     (Test 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6330</th>\n",
       "      <td>State Department says it can't find emails fro...</td>\n",
       "      <td>The State Department told the Republican Natio...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6331</th>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6332</th>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligarc...</td>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligar...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>In Ethiopia, Obama seeks progress on peace, se...</td>\n",
       "      <td>ADDIS ABABA, Ethiopia —President Obama convene...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6334</th>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6335 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0                          You Can Smell Hillary’s Fear   \n",
       "1     Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2           Kerry to go to Paris in gesture of sympathy   \n",
       "3     Bernie supporters on Twitter erupt in anger ag...   \n",
       "4      The Battle of New York: Why This Primary Matters   \n",
       "...                                                 ...   \n",
       "6330  State Department says it can't find emails fro...   \n",
       "6331  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...   \n",
       "6332  Anti-Trump Protesters Are Tools of the Oligarc...   \n",
       "6333  In Ethiopia, Obama seeks progress on peace, se...   \n",
       "6334  Jeb Bush Is Suddenly Attacking Trump. Here's W...   \n",
       "\n",
       "                                                   text label  \n",
       "0     Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1     Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2     U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3     — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4     It's primary day in New York and front-runners...  REAL  \n",
       "...                                                 ...   ...  \n",
       "6330  The State Department told the Republican Natio...  REAL  \n",
       "6331  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...  FAKE  \n",
       "6332   Anti-Trump Protesters Are Tools of the Oligar...  FAKE  \n",
       "6333  ADDIS ABABA, Ethiopia —President Obama convene...  REAL  \n",
       "6334  Jeb Bush Is Suddenly Attacking Trump. Here's W...  REAL  \n",
       "\n",
       "[6335 rows x 3 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5 = pd.read_csv('Test/news.csv', usecols=['title', 'text', 'label'])\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title    0\n",
       "text     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5['cleaned_article'] = df5['title'] + \" \" + df5['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting label into boolean value\n",
    "\n",
    "df5['label'].replace(('REAL', 'FAKE'), (1, 0), inplace=True)\n",
    "#or \n",
    "# df5.label.replace({\"REAL\":1, \"FAKE\":0}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>0</td>\n",
       "      <td>You Can Smell Hillary’s Fear Daniel Greenfield...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>0</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>1</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy U....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>0</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>1</td>\n",
       "      <td>The Battle of New York: Why This Primary Matte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                       You Can Smell Hillary’s Fear   \n",
       "1  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        Kerry to go to Paris in gesture of sympathy   \n",
       "3  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text  label  \\\n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...      0   \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...      0   \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...      1   \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...      0   \n",
       "4  It's primary day in New York and front-runners...      1   \n",
       "\n",
       "                                     cleaned_article  \n",
       "0  You Can Smell Hillary’s Fear Daniel Greenfield...  \n",
       "1  Watch The Exact Moment Paul Ryan Committed Pol...  \n",
       "2  Kerry to go to Paris in gesture of sympathy U....  \n",
       "3  Bernie supporters on Twitter erupt in anger ag...  \n",
       "4  The Battle of New York: Why This Primary Matte...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.drop(['title','text'], axis = 1 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3171\n",
       "0    3164\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae7274e188d4cd7a360487474bfb96d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "093a42a47baa476a98c0b5bace8e630f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2136f8b40ce4e8fa7347bd9d987d008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Featurization\n",
      "Number of punctuations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81aceb97baa04455b525ead0e400d31b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Stopwords\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5d79286add44f93972e0b839b927bc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of question marks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2c3a8219dba4c478b19d70913d72074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Exclamation Marks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0c1878353264d5e9f1fe9b97d48b8cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Sentences\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06a9be27a65c4528872579a7d45fdbca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7f015e19a3a4cf9933e9af7109a5d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS TAGGING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 6335/6335 [03:18<00:00, 31.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning......\n",
      "Special Char\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d163c9aee324804b08e655ac4f69514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article Length\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e90cd72c1a0249bcb7a324324f6ae569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmetization\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c84a0765c73246678af6fa8130139096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Words...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27cf762117954f968de983c206540a17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ca61367c80d4136941be12391bec13a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df5 = data_cleaning(df5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df5['cleaned_article'] = df5['cleaned_article'].apply(lambda x : \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e1116b0b4644588ce1d34ae2010e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Count\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eadec4f7f8244ff9606e0d81ec71ebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Word Count\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c9ccd9af81d44b09a93390a68ba509f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique Words\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15708e546b544aefb2ea7bec2598bb05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Chars\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c0080833096415da2fcd4094b4eaec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_article</th>\n",
       "      <th>num_punctuations</th>\n",
       "      <th>no_of_stopwords</th>\n",
       "      <th>no_of_quesMarks</th>\n",
       "      <th>no_of_exclamation</th>\n",
       "      <th>no_of_sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cc_cd</th>\n",
       "      <th>determiner</th>\n",
       "      <th>...</th>\n",
       "      <th>noun</th>\n",
       "      <th>adverb</th>\n",
       "      <th>verb</th>\n",
       "      <th>article_len</th>\n",
       "      <th>negations</th>\n",
       "      <th>polarity</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>num_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>smell hillary fear daniel greenfield shillman ...</td>\n",
       "      <td>107</td>\n",
       "      <td>1061</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>Negative</td>\n",
       "      <td>51</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>339</td>\n",
       "      <td>74</td>\n",
       "      <td>253</td>\n",
       "      <td>7364</td>\n",
       "      <td>9</td>\n",
       "      <td>0.029606</td>\n",
       "      <td>544</td>\n",
       "      <td>6.755515</td>\n",
       "      <td>373</td>\n",
       "      <td>4218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>watch exact moment paul ryan committed politic...</td>\n",
       "      <td>60</td>\n",
       "      <td>331</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>Positive</td>\n",
       "      <td>20</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>132</td>\n",
       "      <td>23</td>\n",
       "      <td>82</td>\n",
       "      <td>2584</td>\n",
       "      <td>3</td>\n",
       "      <td>0.028472</td>\n",
       "      <td>208</td>\n",
       "      <td>6.658654</td>\n",
       "      <td>172</td>\n",
       "      <td>1592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>kerry paris gesture sympathy secretary state j...</td>\n",
       "      <td>43</td>\n",
       "      <td>358</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>Positive</td>\n",
       "      <td>12</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>131</td>\n",
       "      <td>12</td>\n",
       "      <td>77</td>\n",
       "      <td>2520</td>\n",
       "      <td>6</td>\n",
       "      <td>0.018500</td>\n",
       "      <td>217</td>\n",
       "      <td>6.460829</td>\n",
       "      <td>154</td>\n",
       "      <td>1618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>bernie supporter twitter erupt anger tried war...</td>\n",
       "      <td>76</td>\n",
       "      <td>337</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>Negative</td>\n",
       "      <td>28</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>122</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>2545</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.006044</td>\n",
       "      <td>214</td>\n",
       "      <td>7.186916</td>\n",
       "      <td>161</td>\n",
       "      <td>1751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>battle york primary matter primary york frontr...</td>\n",
       "      <td>53</td>\n",
       "      <td>210</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>Positive</td>\n",
       "      <td>21</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>94</td>\n",
       "      <td>11</td>\n",
       "      <td>67</td>\n",
       "      <td>1833</td>\n",
       "      <td>2</td>\n",
       "      <td>0.111458</td>\n",
       "      <td>144</td>\n",
       "      <td>6.284722</td>\n",
       "      <td>91</td>\n",
       "      <td>1048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6330</th>\n",
       "      <td>1</td>\n",
       "      <td>state department email clinton specialist stat...</td>\n",
       "      <td>78</td>\n",
       "      <td>569</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>Negative</td>\n",
       "      <td>23</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>201</td>\n",
       "      <td>24</td>\n",
       "      <td>145</td>\n",
       "      <td>4023</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.027560</td>\n",
       "      <td>326</td>\n",
       "      <td>6.963190</td>\n",
       "      <td>152</td>\n",
       "      <td>2595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6331</th>\n",
       "      <td>0</td>\n",
       "      <td>stand plutocratic pentagon stand plutocratic p...</td>\n",
       "      <td>383</td>\n",
       "      <td>1929</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>Negative</td>\n",
       "      <td>127</td>\n",
       "      <td>213</td>\n",
       "      <td>...</td>\n",
       "      <td>646</td>\n",
       "      <td>80</td>\n",
       "      <td>267</td>\n",
       "      <td>13722</td>\n",
       "      <td>12</td>\n",
       "      <td>0.028696</td>\n",
       "      <td>1073</td>\n",
       "      <td>7.558248</td>\n",
       "      <td>739</td>\n",
       "      <td>9182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6332</th>\n",
       "      <td>0</td>\n",
       "      <td>antitrump protester tool oligarchy information...</td>\n",
       "      <td>214</td>\n",
       "      <td>1476</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>Negative</td>\n",
       "      <td>75</td>\n",
       "      <td>237</td>\n",
       "      <td>...</td>\n",
       "      <td>569</td>\n",
       "      <td>55</td>\n",
       "      <td>358</td>\n",
       "      <td>11769</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>912</td>\n",
       "      <td>7.162281</td>\n",
       "      <td>531</td>\n",
       "      <td>7443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>1</td>\n",
       "      <td>ethiopia obama seek progress peace security ea...</td>\n",
       "      <td>157</td>\n",
       "      <td>981</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Positive</td>\n",
       "      <td>57</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>323</td>\n",
       "      <td>31</td>\n",
       "      <td>188</td>\n",
       "      <td>6764</td>\n",
       "      <td>4</td>\n",
       "      <td>0.055563</td>\n",
       "      <td>562</td>\n",
       "      <td>6.925267</td>\n",
       "      <td>361</td>\n",
       "      <td>4453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6334</th>\n",
       "      <td>1</td>\n",
       "      <td>bush suddenly attacking trump matter bush sudd...</td>\n",
       "      <td>148</td>\n",
       "      <td>578</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>Positive</td>\n",
       "      <td>24</td>\n",
       "      <td>73</td>\n",
       "      <td>...</td>\n",
       "      <td>225</td>\n",
       "      <td>63</td>\n",
       "      <td>194</td>\n",
       "      <td>4730</td>\n",
       "      <td>14</td>\n",
       "      <td>0.007071</td>\n",
       "      <td>357</td>\n",
       "      <td>6.397759</td>\n",
       "      <td>248</td>\n",
       "      <td>2640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6335 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                    cleaned_article  \\\n",
       "0         0  smell hillary fear daniel greenfield shillman ...   \n",
       "1         0  watch exact moment paul ryan committed politic...   \n",
       "2         1  kerry paris gesture sympathy secretary state j...   \n",
       "3         0  bernie supporter twitter erupt anger tried war...   \n",
       "4         1  battle york primary matter primary york frontr...   \n",
       "...     ...                                                ...   \n",
       "6330      1  state department email clinton specialist stat...   \n",
       "6331      0  stand plutocratic pentagon stand plutocratic p...   \n",
       "6332      0  antitrump protester tool oligarchy information...   \n",
       "6333      1  ethiopia obama seek progress peace security ea...   \n",
       "6334      1  bush suddenly attacking trump matter bush sudd...   \n",
       "\n",
       "      num_punctuations  no_of_stopwords  no_of_quesMarks  no_of_exclamation  \\\n",
       "0                  107             1061                3                  0   \n",
       "1                   60              331                0                  0   \n",
       "2                   43              358                0                  0   \n",
       "3                   76              337                0                  2   \n",
       "4                   53              210                0                  2   \n",
       "...                ...              ...              ...                ...   \n",
       "6330                78              569                0                  1   \n",
       "6331               383             1929                1                  0   \n",
       "6332               214             1476                6                  0   \n",
       "6333               157              981                0                  0   \n",
       "6334               148              578                1                  1   \n",
       "\n",
       "      no_of_sentence sentiment  cc_cd  determiner  ...  noun  adverb  verb  \\\n",
       "0                 87  Negative     51         158  ...   339      74   253   \n",
       "1                 25  Positive     20          44  ...   132      23    82   \n",
       "2                 16  Positive     12          38  ...   131      12    77   \n",
       "3                 17  Negative     28          39  ...   122      20    65   \n",
       "4                 21  Positive     21          34  ...    94      11    67   \n",
       "...              ...       ...    ...         ...  ...   ...     ...   ...   \n",
       "6330              27  Negative     23          62  ...   201      24   145   \n",
       "6331              48  Negative    127         213  ...   646      80   267   \n",
       "6332             100  Negative     75         237  ...   569      55   358   \n",
       "6333              40  Positive     57         109  ...   323      31   188   \n",
       "6334              55  Positive     24          73  ...   225      63   194   \n",
       "\n",
       "      article_len  negations  polarity  word_count  avg_word_len  \\\n",
       "0            7364          9  0.029606         544      6.755515   \n",
       "1            2584          3  0.028472         208      6.658654   \n",
       "2            2520          6  0.018500         217      6.460829   \n",
       "3            2545          3 -0.006044         214      7.186916   \n",
       "4            1833          2  0.111458         144      6.284722   \n",
       "...           ...        ...       ...         ...           ...   \n",
       "6330         4023          7 -0.027560         326      6.963190   \n",
       "6331        13722         12  0.028696        1073      7.558248   \n",
       "6332        11769         13  0.000110         912      7.162281   \n",
       "6333         6764          4  0.055563         562      6.925267   \n",
       "6334         4730         14  0.007071         357      6.397759   \n",
       "\n",
       "      num_unique_words  num_chars  \n",
       "0                  373       4218  \n",
       "1                  172       1592  \n",
       "2                  154       1618  \n",
       "3                  161       1751  \n",
       "4                   91       1048  \n",
       "...                ...        ...  \n",
       "6330               152       2595  \n",
       "6331               739       9182  \n",
       "6332               531       7443  \n",
       "6333               361       4453  \n",
       "6334               248       2640  \n",
       "\n",
       "[6335 rows x 24 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_engineering(df5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop_noword_article(df5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'smell hillary fear daniel greenfield shillman journalism fellow freedom center york writer focusing radical islam final stretch election hillary rodham clinton gone word unprecedented thrown election ought retired unprecedented nominee major political party thats exactly hillary people coma patient waking watching hour hospital assume director james comey hillary opponent election attack obama hillary people circulated letter attacking comey currently medium piece lambasting targeting trump wouldnt surprising clinton ally start running attack leadership warned entire leftwing establishment form lynch continue going hillary credibility attacked medium democrat preemptively head result investigation clinton foundation hillary clinton covert struggle agent obamas people gone explosively public york time compared comey edgar hoover bizarre headline james comey role recall hoover fairly practically admits spouting nonsense boston globe published column calling comeys resignation outdone time editorial claiming scandal attack woman james carville appeared msnbc remind alive insane accused comey coordinating house republican thought vast right wing conspiracy stretch countless medium story charge comey violating procedure know whats procedural violation emailing classified information stored bathroom server senator harry reid sent comey letter accusing violating hatch hatch nice idea relevance obama tenth amendment cable news spectrum quickly filled medium hack glancing wikipedia article hatch table accusing director awkward conspiracy hillary james comey hurt hillary picked hell strange long democrat breathing sigh relief gave hillary clinton prominent public statement elect trump keeping email scandal going trash investigation payroll house republican playing sudden development vladimir putin paul ryan talked taking look anthony weiners comey cunning director lived awkwardly trying navigate political mess trapped leadership political future tied hillary victory bureau apolitical agent want allowed truly mysterious thing hillary associate decided respected federal agency american like hillary clinton enjoys unfavorable rating interesting question hillary strategy deny criminal investigation underway instead associate insisted security review corrected shrugged breezy denial approach given savage assault pretending wrong strategy better picking fight lunatic clinton associate claim possible explanation hillary clinton arrogant lash belief victory near kind hubris plan victory firework display lead declare irritating final mile campaign explanation people panicked going behavior smart focused presidential campaign desperation presidential candidate decides option destroy credibility thats hubris fear reveal original investigation hillary clinton confident ride good reason believing hillary clinton gone place paranoid wreck short space time positive clinton campaign promising unite country replaced desperate flailing operation focused energy fighting reason bizarre behavior clinton campaign decided investigation latest batch email pose threat survival gone fighting unprecedented step born fear hard know fear justified existence fear tell clinton loyalist rigged investigation knew outcome ahead time knew debate question suddenly longer control afraid smell fear wiretap investigation clinton foundation finding email time clintonworld panicked spinmeister clintonworld claimed email scandal smoke thats appearance impropriety substance isnt react smoke respond misguided assault tell hillary clinton ally afraid revelation bigger fundamental illegality email setup email setup preemptive cover clinton campaign panicked badly belief right wrong crime illegal setup meant cover risk exposed clinton weathered countless scandal year protecting time bigger usual corruption bribery sexual assault abuse power followed year bigger damaging allegation come dont want investigator near campaign comey pure intimidation warning senior people value career warned stay away democrat closing rank nominee ugly unprecedented scene stand hillary clinton awkwardly wound numerous scandal election cycle shes shown fear desperation changed afraid buried email huma abedin bring like'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.cleaned_article[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.to_csv(\"Test/test2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining train data into one dataset for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df123 = pd.concat([df1, df2, df3], axis = 0) # Concatinating first three datasets for training purpose\n",
    "df123 = df123.sample(frac = 1) # Mixing/sampling the dataset\n",
    "df123.reset_index(inplace = True, drop = True) # Resetting index number\n",
    "df123.dropna(inplace = True)\n",
    "df123.to_csv('training_set.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
